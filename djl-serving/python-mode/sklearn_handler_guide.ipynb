{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DJL Sklearn Handler Tutorial\n",
    "\n",
    "This notebook shows how to use DJL sklearn handler for model serving on SageMaker.\n",
    "\n",
    "**Prerequisites:**\n",
    "- S3 bucket push access\n",
    "- SageMaker access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sagemaker scikit-learn --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import joblib\n",
    "import json\n",
    "import sys\n",
    "import sklearn\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.session.Session()\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create and Train Sklearn Model\n",
    "\n",
    "DJL Serving's scikit-learn handler supports multiple model persistence formats:\n",
    "\n",
    "**Secure formats (default):**\n",
    "- `skops`: .skops files\n",
    "\n",
    "**Insecure formats (require trust_insecure_model_files=true):**\n",
    "- `joblib`: .joblib, .jl files\n",
    "- `pickle`: .pkl, .pickle files\n",
    "- `cloudpickle`: .pkl, .pickle, .cloudpkl files\n",
    "\n",
    "For security, only skops format is allowed by default. Other formats require setting `option.trust_insecure_model_files=true`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset for demo purposes\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, 'model.joblib')\n",
    "print(\"Model trained and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Using Built-in Handler's Default Handling\n",
    "\n",
    "The scikit-learn handler must be specified as the entry point in the model server options, either in a serving.properties file or via environment variables that are passed to the SageMaker Model object. For more detail, read DJL's deployment guide: https://docs.djl.ai/master/docs/serving/serving/docs/lmi/deployment_guide/deploying-your-endpoint.html.\n",
    "\n",
    "You must specify the model format as well in the model server options (skops, joblib, pickle, or cloudpickle). Additionally, if the model format is not secure (only skops is secure by default), you must set OPTION_TRUST_INSECURE_MODEL_FILES to true. If using skops, set OPTION_SKOPS_TRUSTED_TYPES--for example, option.skops_trusted_types='sklearn.ensemble._forest.RandomForestClassifier,numpy.ndarray'.\n",
    "\n",
    "DJL supports the following file extensions for each format:\n",
    "skops: .skops\n",
    "joblib: .joblib, .jl\n",
    "pickle: .pkl, .pickle\n",
    "cloudpickle: .pkl, .pickle, .cloudpkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.entryPoint=djl_python.sklearn_handler\n",
    "option.model_format=joblib\n",
    "option.trust_insecure_model_files=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir sklearn_basic\n",
    "mv model.joblib sklearn_basic/\n",
    "mv serving.properties sklearn_basic/\n",
    "tar czvf sklearn_basic.tar.gz sklearn_basic/\n",
    "rm -rf sklearn_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: DJL Custom Formatters and Handlers Model\n",
    "\n",
    "You can use DJL Serving's custom decorators to write your own custom pre-processing, prediction, and post-processing code for flexible inference. To do so, include a model.py file in the model directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate model for custom formatters\n",
    "joblib.dump(model, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.entryPoint=djl_python.sklearn_handler\n",
    "option.model_format=joblib\n",
    "option.trust_insecure_model_files=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your model.py file, include the following decorators and signatures. The function names are flexible. Note that if you omit any definition, the default scikit-learn handler logic will be used for initialization, input processing, prediction, and output processing. By default, the handler expects a NumPy array for prediction and returns the prediction as a NumPy array. CSV and JSON input/output are supported by default, with JSON being the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "from djl_python.input_parser import input_formatter, prediction_handler, init_handler\n",
    "from djl_python.output_formatter import output_formatter\n",
    "from djl_python import Input\n",
    "\n",
    "@init_handler\n",
    "def custom_init_fn(model_dir, **kwargs):\n",
    "    \"\"\"Custom model initialization - load with custom logic\"\"\"\n",
    "    print(f\"Python version: {sys.version}\")\n",
    "    print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "    \n",
    "    model_path = os.path.join(model_dir, \"model.joblib\")\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"Custom init: Loaded model with {model.n_estimators} estimators\")\n",
    "    return model\n",
    "\n",
    "@input_formatter\n",
    "def custom_input_fn(inputs: Input, **kwargs):\n",
    "    \"\"\"Custom input processing - expects {\"features\": [...]} format or default {\"inputs\": [...]} format\"\"\"\n",
    "    data = inputs.get_as_json()\n",
    "    features = data.get(\"features\", data.get(\"inputs\", data))\n",
    "    X = np.array(features)\n",
    "    \n",
    "    # Ensure 2D array\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape(1, -1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "@prediction_handler\n",
    "def custom_predict_fn(X, model, **kwargs):\n",
    "    \"\"\"Custom prediction logic - returns both predictions and probabilities\"\"\"\n",
    "    predictions = model.predict(X)\n",
    "    probabilities = model.predict_proba(X)\n",
    "    \n",
    "    return {\n",
    "        \"predictions\": predictions,\n",
    "        \"probabilities\": probabilities\n",
    "    }\n",
    "\n",
    "@output_formatter\n",
    "def custom_output_fn(result):  \n",
    "    \"\"\"Custom output formatting - returns detailed predictions\"\"\"\n",
    "    predictions = result[\"predictions\"]\n",
    "    probabilities = result[\"probabilities\"]\n",
    "    \n",
    "    return {\n",
    "        \"predictions\": predictions.tolist(),\n",
    "        \"probabilities\": probabilities.tolist(),\n",
    "        \"model_type\": \"sklearn_random_forest\",\n",
    "        \"num_samples\": len(predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir sklearn_custom\n",
    "mv model.joblib sklearn_custom/\n",
    "mv model.py sklearn_custom/\n",
    "mv serving.properties sklearn_custom/\n",
    "tar czvf sklearn_custom.tar.gz sklearn_custom/\n",
    "rm -rf sklearn_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: SageMaker Custom Script and ENV Variable Compatibility\n",
    "\n",
    "The scikit-learn handler is also backwards compatible with SageMaker inference scripts that implement model_fn, input_fn, predict_fn, and output_fn. Like the DJL custom formatters, you can omit any number of the four functions and use the default handler logic for the missing function(s). Note that the functions must follow the following signatures:\n",
    "\n",
    "- model_fn(model_dir) where model_dir is the model directory's name.\n",
    "- input_fn(request_body, request_content_type) where request_body is a byte buffer. (request_content_type can also be named content_type)\n",
    "- predict_fn(input_object, model) where input_object is the object returned by input_fn.\n",
    "- output_fn(prediction, response_content_type) where prediction is returned by predict_fn and output_fn returns a byte array of data serialized to the specified type. (response_content_type can also be named accept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate model for SageMaker format\n",
    "joblib.dump(model, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.entryPoint=djl_python.sklearn_handler\n",
    "option.model_format=joblib\n",
    "option.trust_insecure_model_files=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import sklearn\n",
    "import logging\n",
    "\n",
    "# Configure logging to ensure it appears\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Load the scikit-learn model from the model directory.\"\"\"\n",
    "    model_path = os.path.join(model_dir, \"model.joblib\")\n",
    "    model = joblib.load(model_path)\n",
    "    return model\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"Parse input data for inference.\"\"\"\n",
    "    if request_content_type == \"application/json\":\n",
    "        data = json.loads(request_body)\n",
    "        if isinstance(data, dict):\n",
    "            features = data.get(\"features\", data.get(\"inputs\", data))\n",
    "        else:\n",
    "            features = data\n",
    "        result = np.array(features)\n",
    "        return result\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {request_content_type}\")\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Run prediction on the input data.\"\"\"\n",
    "    if input_data.ndim == 1:\n",
    "        input_data = input_data.reshape(1, -1)\n",
    "    \n",
    "    prediction = model.predict(input_data)\n",
    "    probabilities = model.predict_proba(input_data)\n",
    "    return {\"prediction\": prediction, \"probabilities\": probabilities}\n",
    "\n",
    "def output_fn(prediction, response_content_type):\n",
    "    \"\"\"Format the prediction output.\"\"\"\n",
    "    result = {\n",
    "        \"prediction\": prediction[\"prediction\"].tolist(),\n",
    "        \"probabilities\": prediction[\"probabilities\"].tolist(),\n",
    "        \"custom_sagemaker_functions\": \"WORKING\",\n",
    "        \"sklearn_version\": sklearn.__version__\n",
    "    }\n",
    "    json_result = json.dumps(result)\n",
    "    return json_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir sklearn_sagemaker\n",
    "mv model.joblib sklearn_sagemaker/\n",
    "mv model.py sklearn_sagemaker/\n",
    "mv serving.properties sklearn_sagemaker/\n",
    "tar czvf sklearn_sagemaker.tar.gz sklearn_sagemaker/\n",
    "rm -rf sklearn_sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Deploy to SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "TODO: Uncomment this once container is officially available.\n",
    "# Get DJL container image \n",
    "image_uri = image_uris.retrieve(\n",
    "    framework=\"djl-inference\",\n",
    "    region=region,\n",
    "    version=\"0.35.0\"\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "image_uri = \"875423407011.dkr.ecr.us-west-2.amazonaws.com/djl-serving-demo-cpufull:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload all models to S3\n",
    "s3_code_prefix = \"sklearn-djl/code\"\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Upload all three model variants\n",
    "models = ['sklearn_basic.tar.gz', 'sklearn_custom.tar.gz', 'sklearn_sagemaker.tar.gz']\n",
    "model_uris = {}\n",
    "\n",
    "for model_file in models:\n",
    "    model_name = model_file.replace('.tar.gz', '')\n",
    "    model_uri = sess.upload_data(model_file, bucket, f\"{s3_code_prefix}/{model_name}\")\n",
    "    model_uris[model_name] = model_uri\n",
    "    print(f\"{model_name} uploaded to: {model_uri}\")\n",
    "\n",
    "# Choose which model to deploy\n",
    "selected_model = 'sklearn_sagemaker'  # Change this as needed\n",
    "code_artifact = model_uris[selected_model]\n",
    "print(f\"\\nSelected model for deployment: {selected_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following environment variables are now supported in the DJL serving container:\n",
    "\n",
    "- SAGEMAKER_MAX_REQUEST_SIZE\n",
    "- SAGEMAKER_NUM_MODEL_WORKERS\n",
    "- SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\n",
    "- SAGEMAKER_MODEL_SERVER_TIMEOUT_SECONDS\n",
    "- SAGEMAKER_MODEL_SERVER_VMARGS\n",
    "- SAGEMAKER_STARTUP_TIMEOUT\n",
    "- SAGEMAKER_MAX_PAYLOAD_IN_MB\n",
    "\n",
    "You can set these environment variables in the env parameter when creating your SageMaker Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "# Example of how to specify environment variables \n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=code_artifact, \n",
    "    role=role,\n",
    "    predictor_cls=Predictor, # Include predictor_cls parameter if using customized DJL container via ECR URI\n",
    "    # specify all environment variable configs in this map (note that SAGEMAKER_MAX_REQUEST_SIZE is in bytes)\n",
    "    env={\n",
    "        \"SAGEMAKER_NUM_MODEL_WORKERS\": \"2\",\n",
    "        \"SAGEMAKER_MAX_REQUEST_SIZE\": \"10485760\",  \n",
    "        \"SAGEMAKER_MODEL_SERVER_TIMEOUT_SECONDS\": \"300\",\n",
    "    }\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "# Create SageMaker model\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=code_artifact,\n",
    "    role=role,\n",
    "    predictor_cls=Predictor\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy endpoint\n",
    "instance_type = \"ml.m5.large\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"sklearn-djl\")\n",
    "\n",
    "print(f\"Endpoint name: {endpoint_name}\")\n",
    "\n",
    "# Check if model variable exists and has deploy method\n",
    "print(f\"Model object: {model}\")\n",
    "print(f\"Model type: {type(model)}\")\n",
    "\n",
    "try:\n",
    "    predictor = model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=instance_type,\n",
    "        endpoint_name=endpoint_name,\n",
    "        serializer=serializers.JSONSerializer()\n",
    "    )\n",
    "    print(f\"Predictor created: {predictor}\")\n",
    "except Exception as e:\n",
    "    print(f\"Deployment error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test Inference\n",
    "\n",
    "By default, the scikit-learn handler supports CSV and JSON inputs/outputs. CSVs must use a comma as the delimiter and separate samples with new lines. JSON inputs must either be a dictionary in the form `({\"input\": [...]})` or an array of arrays. Examples can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test basic DJL-compatible JSON formats ({\"inputs\": [...]} or an array of arrays (list of lists))\n",
    "basic_payload = {\n",
    "    \"inputs\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "}\n",
    "\n",
    "# Note that this doesn't work with xgboost_custom due to how the the input formatter is implemented--expect an error.\n",
    "list_payload = [[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]]\n",
    "\n",
    "# Note that result is a byte buffer because we didn't specify a deserializer\n",
    "result = predictor.predict(basic_payload)\n",
    "print(\"Basic format result:\")\n",
    "print(result)\n",
    "print(\"Decoded basic format result:\")\n",
    "print(result.decode('utf-8'))\n",
    "\n",
    "result = predictor.predict(list_payload)\n",
    "print(\"List format result:\")\n",
    "print(result)\n",
    "print(\"Decoded list format result:\")\n",
    "print(result.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test custom format (works with models with custom formatters)\n",
    "custom_payload = {\n",
    "    \"features\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "}\n",
    "\n",
    "try:\n",
    "    result = predictor.predict(custom_payload)\n",
    "    print(\"Custom format result:\")\n",
    "    print(result)\n",
    "    print(\"Decoded custom format result:\")\n",
    "    print(result.decode('utf-8'))\n",
    "except Exception as e:\n",
    "    print(f\"Custom format not supported by this model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch prediction\n",
    "batch_payload = {\n",
    "    \"inputs\": [\n",
    "        [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0],\n",
    "        [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0],\n",
    "        [3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0]\n",
    "    ]\n",
    "}\n",
    "\n",
    "result = predictor.predict(batch_payload)\n",
    "print(\"Batch prediction result:\")\n",
    "print(result)\n",
    "print(\"Decoded batch format result:\")\n",
    "print(result.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up resources\n",
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "model.delete_model()\n",
    "print(\"Resources cleaned up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test payloads for different scenarios\n",
    "\n",
    "# Single sample\n",
    "single_sample = {\n",
    "    \"inputs\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "}\n",
    "\n",
    "# Batch samples\n",
    "batch_samples = {\n",
    "    \"inputs\": [\n",
    "        [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0],\n",
    "        [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Custom format (for custom formatters above) using \"features\" instead of \"inputs\"\n",
    "custom_format = {\n",
    "    \"features\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "}\n",
    "\n",
    "# CSV format (note: switch serializer to CSVSerializer if using CSV inputs. Note that CSV inputs won't work with the provided \n",
    "# custom formatter/handler models above due to their custom function implementation but will work with the basic model.)\n",
    "csv_single = \"1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0\"\n",
    "csv_batch = \"\"\"1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0\n",
    "2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0\"\"\"\n",
    "\n",
    "print(\"Single sample JSON:\")\n",
    "print(json.dumps(single_sample, indent=2))\n",
    "\n",
    "print(\"\\nBatch samples JSON:\")\n",
    "print(json.dumps(batch_samples, indent=2))\n",
    "\n",
    "print(\"\\nCustom format JSON:\")\n",
    "print(json.dumps(custom_format, indent=2))\n",
    "\n",
    "print(\"\\nCSV single:\")\n",
    "print(csv_single)\n",
    "\n",
    "print(\"\\nCSV batch:\")\n",
    "print(csv_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated how to use DJL's sklearn handler with different approaches:\n",
    "\n",
    "1. **Basic Handler**: Using the built-in sklearn handler with default processing\n",
    "2. **Custom DJL Formatters**: Using DJL's decorators for custom input/output processing\n",
    "3. **SageMaker Compatible**: Using SageMaker's standard inference functions\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "- **Model Formats**: Only `skops` is secure by default. Other formats (`joblib`, `pickle`, `cloudpickle`) require `option.trust_insecure_model_files=true`\n",
    "- **File Extensions**: \n",
    "  - `skops`: .skops\n",
    "  - `joblib`: .joblib, .jl\n",
    "  - `pickle`: .pkl, .pickle\n",
    "  - `cloudpickle`: .pkl, .pickle, .cloudpkl\n",
    "- **Custom Processing**: Use DJL decorators (`@init_handler`, `@input_formatter`, `@prediction_handler`, `@output_formatter`) for flexible inference\n",
    "- **SageMaker Compatibility**: Implement standard SageMaker functions (`model_fn`, `input_fn`, `predict_fn`, `output_fn`) for PySDK compatibility\n",
    "\n",
    "For more information, see the [DJL Serving documentation](https://docs.djl.ai/docs/serving/index.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
