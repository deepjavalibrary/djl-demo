{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "946d5a3d",
   "metadata": {},
   "source": [
    "# Llama3 Stateful Inference with LMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35756ca1",
   "metadata": {},
   "source": [
    "This notebook will demonstrates how to use LMI container to deploy Llama Model with stateful sessions enabled.\n",
    "\n",
    "Stateful sessions is a feature that allows all requests within the same session routed to the same instance, allowing your ML application to reuse previously processed information. This reduces latency and enhances the overall user experience.\n",
    "\n",
    "Stateful sessions configurations:\n",
    "\n",
    "* `OPTION_ENABLE_STATEFUL_SESSIONS`: Whether to enable stateful sessions support, defaults to true.\n",
    "* `OPTION_SESSIONS_PATH`: Specifies the path where session data is saved, defaults to \"/dev/shm/djl_sessions\".\n",
    "* `OPTION_SESSIONS_EXPIRATION`: Specifies time in seconds a session remains valid before it expires, defaults to 1200."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e3b6d",
   "metadata": {},
   "source": [
    "## Install Packages and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a4ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker boto3 huggingface-hub --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb06ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sagemaker.utils import name_from_base\n",
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6dca13",
   "metadata": {},
   "source": [
    "## Create SageMaker Model and Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc6e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "model_bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1008e38",
   "metadata": {},
   "source": [
    "### Configure model container environment\n",
    "\n",
    "Create a container environment for the hosting container. LMI container parameters can be found in the [LMI User Guides](https://docs.djl.ai/master/docs/serving/serving/docs/lmi/user_guides/index.html).\n",
    "\n",
    "We configure the session expiration to 3600 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f66cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = {\n",
    "    \"HF_MODEL_ID\": \"unsloth/llama-3-8b-Instruct\",\n",
    "    \"OPTION_ASYNC_MODE\": \"true\",\n",
    "    \"OPTION_ROLLING_BATCH\": \"disable\",\n",
    "    \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\",\n",
    "    \"OPTION_MAX_ROLLING_BATCH_SIZE\": \"32\",\n",
    "    \"OPTION_TENSOR_PARALLEL_DEGREE\": \"max\",\n",
    "    \"OPTION_SESSIONS_EXPIRATION\": \"3600\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27727b48",
   "metadata": {},
   "source": [
    "### Create a model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e67228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_uri = image_uris.retrieve(\n",
    "#         framework=\"djl-lmi\",\n",
    "#         region=region,\n",
    "#         version=\"0.34.0\"\n",
    "# )\n",
    "image_uri = \"763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.34.0-lmi16.0.0-cu128\"\n",
    "model_name = name_from_base(\"llama-3-8b-instruct-stateful\")\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        \"Image\": image_uri,\n",
    "        \"Environment\": env,\n",
    "    },\n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c33e3",
   "metadata": {},
   "source": [
    "### Create an endpoint configuration\n",
    "\n",
    "We create an endpoint configuration with an initial deployment of 2 instances of type ml.g6.12xlarge. These 2 instances will serve traffic for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8699f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g6.12xlarge\",\n",
    "            \"InitialInstanceCount\": 2,\n",
    "            \"ModelDataDownloadTimeoutInSeconds\": 1800,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 1800,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(f\"endpoint_name: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ad681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3ee53a",
   "metadata": {},
   "source": [
    "## Start Session\n",
    "\n",
    "To start a session with a stateful model, send an `InvokeEndpoint` request. In the request payload, set \"requestType\" to \"NEW_SESSION\" to start a new session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"requestType\": \"NEW_SESSION\"\n",
    "}\n",
    "payload = json.dumps(payload)\n",
    "\n",
    "create_session_response = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType=\"application/json\",\n",
    "    SessionId=\"NEW_SESSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617abaf7",
   "metadata": {},
   "source": [
    "The LMI container handles the request by starting a new session. The container provides the session ID and expiration timestamp (UTC timezone) by setting the following HTTP header in the response:\n",
    "\n",
    "```\n",
    "X-Amzn-SageMaker-Session-Id: session_id; Expires=yyyy-mm-ddThh:mm:ssZ\n",
    "```\n",
    "\n",
    "We can extract the session ID from the invoke_endpoint response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4af56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = create_session_response['ResponseMetadata']['HTTPHeaders']['x-amzn-sagemaker-new-session-id'].split(';')[0]\n",
    "\n",
    "print(f\"session_id: {session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680b38a",
   "metadata": {},
   "source": [
    "## Make Inference Requests\n",
    "\n",
    "To use the same session for a subsequent inference request, the client sends another `InvokeEndpoint` request, specifying the session ID in the `SessionId` parameter. SageMaker platform then routes the request to the same ML instance where the session was started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84948200",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "response_model = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps({\"inputs\": \"What is Amazon SageMaker?\"}),\n",
    "    ContentType=\"application/json\",\n",
    "    SessionId=session_id\n",
    ")\n",
    "\n",
    "response_model[\"Body\"].read().decode(\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d434c23",
   "metadata": {},
   "source": [
    "## Close Session\n",
    "\n",
    "To close a session, the client sends a final `InvokeEndpoint` request, providing the session ID in the `SessionId` parameter and setting \"requestType\" to \"CLOSE\" in the request payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df21aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"requestType\": \"CLOSE\"\n",
    "}\n",
    "payload = json.dumps(payload)\n",
    "\n",
    "close_session_response = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType=\"application/json\",\n",
    "    SessionId=session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2113a76",
   "metadata": {},
   "source": [
    "The container returns the session ID by setting the following HTTP header in the response:\n",
    "\n",
    "```\n",
    "X-Amzn-SageMaker-Closed-Session-Id: session_id\n",
    "```\n",
    "\n",
    "We can extract the closed session ID from the invoke_endpoint response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_session_id = close_session_response['ResponseMetadata']['HTTPHeaders']['x-amzn-sagemaker-closed-session-id']\n",
    "\n",
    "print(f\"closed_session_id: {closed_session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef62f3e",
   "metadata": {},
   "source": [
    "## Clean up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baadd61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
