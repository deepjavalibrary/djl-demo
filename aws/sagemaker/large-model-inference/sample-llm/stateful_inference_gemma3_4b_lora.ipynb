{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6decc57",
   "metadata": {},
   "source": [
    "# Gemma3 Multi-Adapter Serving with Stateful Inference using LMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c9633d",
   "metadata": {},
   "source": [
    "This notebook will demonstrates how to use LMI container to serve Gemma3 Multi-Adapter LoRA with stateful sessions enabled.\n",
    "\n",
    "Stateful sessions is a feature that allows all requests within the same session routed to the same instance, allowing your ML application to reuse previously processed information. This reduces latency and enhances the overall user experience.\n",
    "\n",
    "Stateful sessions configurations:\n",
    "\n",
    "* `OPTION_ENABLE_STATEFUL_SESSIONS`: Whether to enable stateful sessions support, defaults to true.\n",
    "* `OPTION_SESSIONS_PATH`: Specifies the path where session data is saved, defaults to \"/dev/shm/djl_sessions\".\n",
    "* `OPTION_SESSIONS_EXPIRATION`: Specifies time in seconds a session remains valid before it expires, defaults to 1200."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab4371a",
   "metadata": {},
   "source": [
    "## Install Packages and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709f408-04a5-4b75-8f0e-be15d92aa286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install sagemaker boto3 transformers huggingface-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccf5186-b82d-42e4-af4e-06296e9c0242",
   "metadata": {},
   "source": [
    "## Deploy to SageMaker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2735f30-b745-496e-86e5-152f55d09e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "print(f\"boto3 version: {boto3.__version__}\")\n",
    "print(f\"sagemaker version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef18c2bb-f6a4-4a6a-86ee-4eda9f27d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name\n",
    "\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "sm_runtime = boto3.client(service_name=\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49bfe20-b17a-4ca4-881a-6abb45415d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_image_uri = f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.34.0-lmi16.0.0-cu128\"\n",
    "\n",
    "print(f\"Inference container image: {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a8f39-2489-4835-871e-04f0c0a405ec",
   "metadata": {},
   "source": [
    "### Download and upload adapter weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468fba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download(\"Cossale/poetry-gemma3-4B-LoRA\", local_dir=\"./adapter1\", local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf709d5-0d51-4713-98a7-cb5f4c58da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# PLEASE NOTE - Adapter files must be in \"tar.gz\" file and uploaded to S3\n",
    "#\n",
    "\n",
    "adapter_filename = \"adapter.tar.gz\"\n",
    "adapter_s3_uri = f\"s3://{bucket}/gemma-3-4b-adapter/{adapter_filename}\"\n",
    "\n",
    "print(adapter_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e90d7-082f-4f7f-bffc-3ca5c653dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd adapter1 && tar -czvf ../{adapter_filename} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609cf7b9-57c7-4e12-ac39-1cc8aaee8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {adapter_filename} {adapter_s3_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e50c14",
   "metadata": {},
   "source": [
    "### Create SageMaker Model and Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01606852-3782-4bfd-831c-a1c7a2fa3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.compute_resource_requirements.resource_requirements import ResourceRequirements\n",
    "\n",
    "model_id = \"unsloth/gemma-3-4b-it\"\n",
    "\n",
    "model_name = endpoint_name = \"IC-endpoint-gemma3\"\n",
    "base_inference_component_name = \"base-\" + model_name\n",
    "\n",
    "env = {\n",
    "    \"HF_MODEL_ID\": model_id,\n",
    "    \"SERVING_FAIL_FAST\": \"True\",\n",
    "    \"OPTION_TENSOR_PARALLEL_DEGREE\": \"max\",\n",
    "    \"OPTION_ASYNC_MODE\": \"true\",\n",
    "    \"OPTION_ROLLING_BATCH\": \"disable\",\n",
    "    \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\",\n",
    "    \"OPTION_ENABLE_LORA\": \"true\",\n",
    "    \"OPTION_MAX_LORAS\": \"4\",\n",
    "    \"OPTION_MAX_CPU_LORAS\": \"8\",\n",
    "    \"OPTION_MAX_LORA_RANK\": \"64\",\n",
    "}\n",
    "\n",
    "lmi_model = sagemaker.Model(image_uri = inference_image_uri,\n",
    "                            env = env,\n",
    "                            role = role,\n",
    "                            name = model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e65c1-b469-4f91-b823-70c24d2f21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmi_model.deploy(instance_type = \"ml.g6.12xlarge\",\n",
    "                 initial_instance_count = 1,\n",
    "                 container_startup_health_check_timeout = 600,\n",
    "                 endpoint_name = endpoint_name,\n",
    "                 endpoint_type = sagemaker.enums.EndpointType.INFERENCE_COMPONENT_BASED,\n",
    "                 inference_component_name = base_inference_component_name,\n",
    "                 resources = ResourceRequirements(requests={\"num_accelerators\": 1, \"memory\": 4096, \"copies\": 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03e578c-37e8-4d5d-9f63-b8ae9b99b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ic1_adapter_name = f\"ic1-adapter-{model_name}\"\n",
    "\n",
    "adapter_create_inference_component_response = sm_client.create_inference_component(\n",
    "    InferenceComponentName = ic1_adapter_name,\n",
    "    EndpointName = endpoint_name,\n",
    "    Specification={\n",
    "        \"BaseInferenceComponentName\": base_inference_component_name,\n",
    "        \"Container\": {\n",
    "            \"ArtifactUrl\": adapter_s3_uri\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "sess.wait_for_inference_component(ic1_adapter_name)\n",
    "\n",
    "print(f\"\\nCreated Adapter inference component ARN: {adapter_create_inference_component_response['InferenceComponentArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f40b60-80d7-42b9-95ec-cf1532cf56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "cw_path = urllib.parse.quote_plus(f'/aws/sagemaker/InferenceComponents/{base_inference_component_name}', safe='', encoding=None, errors=None)\n",
    "\n",
    "print(f'You can view your inference component logs here:\\n\\n https://{region}.console.aws.amazon.com/cloudwatch/home?region={region}#logsV2:log-groups/log-group/{cw_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c1b0c",
   "metadata": {},
   "source": [
    "## Start Session\n",
    "\n",
    "To start a session with a stateful model, send an `InvokeEndpoint` request. In the request payload, set \"requestType\" to \"NEW_SESSION\" to start a new session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105618b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"requestType\": \"NEW_SESSION\"\n",
    "}\n",
    "payload = json.dumps(payload)\n",
    "\n",
    "create_session_response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    InferenceComponentName=base_inference_component_name,\n",
    "    Body=payload,\n",
    "    ContentType=\"application/json\",\n",
    "    SessionId=\"NEW_SESSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb1160",
   "metadata": {},
   "source": [
    "The LMI container handles the request by starting a new session. The container provides the session ID and expiration timestamp (UTC timezone) by setting the following HTTP header in the response:\n",
    "\n",
    "```\n",
    "X-Amzn-SageMaker-Session-Id: session_id; Expires=yyyy-mm-ddThh:mm:ssZ\n",
    "```\n",
    "\n",
    "We can extract the session ID from the invoke_endpoint response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402aadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = create_session_response['ResponseMetadata']['HTTPHeaders']['x-amzn-sagemaker-new-session-id'].split(';')[0]\n",
    "\n",
    "print(f\"session_id: {session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe6c722",
   "metadata": {},
   "source": [
    "## Make Inference Requests\n",
    "\n",
    "To use the same session for a subsequent inference request, the client sends another `InvokeEndpoint` request, specifying the session ID in the `SessionId` parameter. SageMaker platform then routes the request to the same ML instance where the session was started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17827d73-c596-429d-9a9c-528e645762df",
   "metadata": {},
   "source": [
    "### Invoke Base IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f57594-0d15-4a09-bd48-85a50f915329",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload={\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Name popular places to visit in London?\"}\n",
    "    ],\n",
    "    \"temperature\": 0.9,\n",
    "    \"max_tokens\": 256,\n",
    "}\n",
    "\n",
    "component_to_invoke = base_inference_component_name\n",
    "\n",
    "response_model = sm_runtime.invoke_endpoint(\n",
    "    EndpointName = endpoint_name,\n",
    "    InferenceComponentName = component_to_invoke,\n",
    "    Body = json.dumps(payload),\n",
    "    ContentType = \"application/json\",\n",
    "    SessionId=session_id\n",
    ")\n",
    "\n",
    "base_response = json.loads(response_model[\"Body\"].read().decode(\"utf8\"))[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(f'Base Model Response:\\n\\n {base_response}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7792b0d9-1360-48fd-b2af-b3b6e8bf4dc4",
   "metadata": {},
   "source": [
    "### Invoke Adapter IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6776a96-a012-4a8f-ac8f-a2c88eb66643",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload={\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Name popular places to visit in London?\"}\n",
    "    ],\n",
    "    \"temperature\": 0.9,\n",
    "    \"max_tokens\": 256,\n",
    "}\n",
    "\n",
    "component_to_invoke = ic1_adapter_name\n",
    "\n",
    "response_model = sm_runtime.invoke_endpoint(\n",
    "    EndpointName = endpoint_name,\n",
    "    InferenceComponentName = component_to_invoke,\n",
    "    Body = json.dumps(payload),\n",
    "    ContentType = \"application/json\",\n",
    "    SessionId=session_id\n",
    ")\n",
    "\n",
    "adapter_response = json.loads(response_model[\"Body\"].read().decode(\"utf8\"))[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(f'Adapter Response:\\n\\n {adapter_response}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493194fc",
   "metadata": {},
   "source": [
    "## Close Session\n",
    "\n",
    "To close a session, the client sends a final `InvokeEndpoint` request, providing the session ID in the `SessionId` parameter and setting \"requestType\" to \"CLOSE\" in the request payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2339783",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"requestType\": \"CLOSE\"\n",
    "}\n",
    "payload = json.dumps(payload)\n",
    "\n",
    "close_session_response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    InferenceComponentName=base_inference_component_name,\n",
    "    Body=payload,\n",
    "    ContentType=\"application/json\",\n",
    "    SessionId=session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775982fb",
   "metadata": {},
   "source": [
    "The container returns the session ID by setting the following HTTP header in the response:\n",
    "\n",
    "```\n",
    "X-Amzn-SageMaker-Closed-Session-Id: session_id\n",
    "```\n",
    "\n",
    "We can extract the closed session ID from the invoke_endpoint response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96163acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_session_id = close_session_response['ResponseMetadata']['HTTPHeaders']['x-amzn-sagemaker-closed-session-id']\n",
    "\n",
    "print(f\"closed_session_id: {closed_session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73c8930",
   "metadata": {},
   "source": [
    "## Clean up Resources\n",
    "\n",
    "If you need to delete an adapter, call the `delete_inference_component` API with the IC name to remove it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_inference_component(ic1_adapter_name, wait = True)\n",
    "print(f'Adapter Component {ic1_adapter_name} deleted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129cc5cb",
   "metadata": {},
   "source": [
    "Deleting the base model IC will automatically delete the base IC and any associated adapter ICs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae6ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_inference_component(base_inference_component_name, wait = True)\n",
    "\n",
    "print(f'Base Component {base_inference_component_name} deleted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af8bfe",
   "metadata": {},
   "source": [
    "Clean up the running endpoint and its configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "print(f'Endpoint {endpoint_name} deleted.')\n",
    "\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "print(f'Endpoint Configuration {endpoint_name} deleted.')\n",
    "\n",
    "sess.delete_model(model_name)\n",
    "print(f'Model {model_name} deleted.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
