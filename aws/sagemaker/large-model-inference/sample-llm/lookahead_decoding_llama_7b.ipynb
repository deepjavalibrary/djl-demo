{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a329f0",
   "metadata": {},
   "source": [
    "# Lookahead Decoding with LLAMA 7B\n",
    "In this tutorial, you will use LMI container from DLC to SageMaker and run inference with it.\n",
    "\n",
    "Please make sure the following permission granted before running the notebook:\n",
    "\n",
    "- S3 bucket push access\n",
    "- SageMaker access\n",
    "\n",
    "## Step 1: Let's bump up SageMaker and import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67fa3208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sagemaker --upgrade  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9ac353",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81deac79",
   "metadata": {},
   "source": [
    "## Step 2: Start preparing model artifacts\n",
    "In LMI contianer, we expect some artifacts to help setting up the model\n",
    "- serving.properties (required): Defines the model server settings\n",
    "- model.py (optional): A python file to define the core inference logic\n",
    "- requirements.txt (optional): Any additional pip wheel need to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b011bf5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.model_id=daryl149/llama-2-7b-chat-hf\n",
    "option.task=text-generation\n",
    "option.tensor_parallel_degree=1\n",
    "option.entryPoint=model.py\n",
    "option.device_map=auto\n",
    "option.dtype=fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c629b87-e9b5-4f00-b07d-770b26619b22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "transformers==4.34.0\n",
    "accelerate==0.23.0\n",
    "git+https://github.com/nd7141/LookaheadDecoding.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ab053",
   "metadata": {},
   "source": [
    "In this step, we will try to override the [default HuggingFace handler](https://github.com/deepjavalibrary/djl-serving/blob/0.24.0-dlc/engines/python/setup/djl_python/huggingface.py#L202) provided by DJLServing. We will add an extra parameter checker called `password` to see if password is correct in the payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19d6798b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "from djl_python.huggingface import HuggingFaceService\n",
    "from djl_python import Output\n",
    "from djl_python.encode_decode import encode, decode\n",
    "import logging\n",
    "import json\n",
    "import types\n",
    "import os \n",
    "os.environ[\"USE_LADE\"]=\"1\"\n",
    "import lade\n",
    "lade.augment_all()\n",
    "lade.config_lade(LEVEL=5, WINDOW_SIZE=7, GUESS_SET_SIZE=7, DEBUG=0)\n",
    "\n",
    "_service = HuggingFaceService()\n",
    "\n",
    "def handle(inputs):\n",
    "    if not _service.initialized:\n",
    "        _service.initialize(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        # initialization request\n",
    "        return None\n",
    "\n",
    "    return _service.inference(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0142973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mymodel/\n",
      "mymodel/model.py\n",
      "mymodel/requirements.txt\n",
      "mymodel/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "rm -rf mymodel\n",
    "mkdir mymodel\n",
    "cp serving.properties mymodel/\n",
    "cp model.py mymodel/\n",
    "cp requirements.txt mymodel/\n",
    "tar czvf mymodel.tar.gz mymodel/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc1dc81-c56c-498f-990a-463825e5130f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb5e21-ed96-4029-85d7-6cb37b1978b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e58cf33",
   "metadata": {},
   "source": [
    "## Step 3: Start building SageMaker endpoint\n",
    "In this step, we will build SageMaker endpoint from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d955679",
   "metadata": {},
   "source": [
    "### Getting the container image URI\n",
    "\n",
    "[Large Model Inference available DLC](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a174b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = image_uris.retrieve(\n",
    "        framework=\"djl-deepspeed\",\n",
    "        region=sess.boto_session.region_name,\n",
    "        version=\"0.24.0\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11601839",
   "metadata": {},
   "source": [
    "### Upload artifact on S3 and create SageMaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38b1e5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-west-2-393382581720/large-model-lmi/code/mymodel.tar.gz\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "s3_code_prefix = \"large-model-lmi/code\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "code_artifact = sess.upload_data(\"mymodel.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=code_artifact, role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f39f6",
   "metadata": {},
   "source": [
    "### 4.2 Create SageMaker endpoint\n",
    "\n",
    "You need to specify the instance to use and endpoint names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e0e61cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: lmi-model-lade-2023-11-22-17-39-35-098\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "--------------!Deployment time: 455.41 sec\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"lmi-model-lade\")\n",
    "print('Endpoint name:', endpoint_name)\n",
    "\n",
    "start = time.time()\n",
    "model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             endpoint_name=endpoint_name,\n",
    "             container_startup_health_check_timeout=1800\n",
    "            )\n",
    "finish = time.time()\n",
    "print(f'Deployment time: {finish-start:.2f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fddab917-fda9-4eaf-8433-6c6ef7fc8c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# our requests and responses will be in json format so we specify the serializer and the deserializer\n",
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63ee65",
   "metadata": {},
   "source": [
    "## Step 5: Test and benchmark the inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79786708",
   "metadata": {},
   "source": [
    "Firstly let's try to run with a wrong inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bcef095",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 28.63\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "results = predictor.predict(\n",
    "    {\"inputs\": \"Write 1000 words text about risks of AI\", \"parameters\": {\"max_new_tokens\":1024, \"do_sample\": False}}\n",
    ")\n",
    "finish = time.time()\n",
    "print(f'Time {finish-start:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6bf6d",
   "metadata": {},
   "source": [
    "Then let's run with the right one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95e484a6-b26c-4438-9ee5-d4b5909f2f62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[\\n  {\\n    \"generated_text\":\"Write 1000 words text about risks of AI and how to mitigate them\\\\n\\\\nArtificial intelligence (AI) has the potential to revolutionize numerous industries and aspects of society, from healthcare and education to transportation and entertainment. However, as with any powerful technology, there are risks associated with AI that must be carefully managed in order to ensure its safe and ethical use. In this article, we will explore some of the key risks of AI and discuss strategies for mitigating them.\\\\n1. Bias and discrimination: AI systems can perpetuate and amplify existing biases and discrimination in society, leading to unfair outcomes and unequal treatment of certain groups. For example, an AI-powered hiring tool may inadvertently discriminate against female or minority candidates, leading to a lack of diversity in the workplace. To mitigate this risk, it is essential to ensure that AI systems are designed and trained on diverse and representative data sets, and that they are regularly audited and tested for bias.\\\\n2. Job displacement: As AI systems become more advanced and capable, there is a risk that they will displace human workers, particularly in industries where tasks are repetitive or can be easily automated. This could lead to significant job losses and social upheaval. To mitigate this risk, it is important to invest in education and retraining programs that prepare workers for the jobs of the future, and to ensure that the benefits of AI are shared fairly among all members of society.\\\\n3. Security and privacy risks: AI systems can potentially compromise security and privacy by collecting and processing large amounts of personal data, which could be used for malicious purposes. For example, an AI-powered surveillance system could be used to monitor and track individuals without their consent. To mitigate this risk, it is essential to ensure that AI systems are designed with robust security and privacy controls, and that they are subject to regular security audits and testing.\\\\n4. Autonomous weapons: The development of autonomous weapons, such as drones and other lethal autonomous robots, raises significant ethical concerns. These systems could be used to wage war without human intervention, leading to significant loss of life and unintended consequences. To mitigate this risk, it is essential to establish clear ethical guidelines and regulations around the development and use of autonomous weapons, and to ensure that they are subject to rigorous testing and oversight.\\\\n5. Unintended consequences: AI systems can have unintended consequences, particularly when they are complex and interconnected. For example, an AI-powered traffic management system could inadvertently create traffic jams or accidents, leading to significant disruptions and safety risks. To mitigate this risk, it is essential to ensure that AI systems are designed with built-in safeguards and contingencies, and that they are regularly tested and updated to account for changing conditions and unforeseen events.\\\\n6. Lack of transparency: AI systems can be complex and difficult to understand, making it challenging to identify and address problems or biases. To mitigate this risk, it is essential to ensure that AI systems are designed with transparency and explainability in mind, and that they are subject to regular audits and testing to ensure that they are functioning as intended.\\\\n7. Dependence on AI: As AI systems become more integrated into various aspects of society, there is a risk that humans will become too dependent on them, leading to a loss of critical thinking skills and problem-solving abilities. To mitigate this risk, it is essential to ensure that AI systems are designed to augment human capabilities, rather than replace them, and that they are used in a way that promotes human development and growth.\\\\n8. Unregulated use: The use of AI is largely unregulated, which can lead to significant risks and challenges. For example, the use of AI in healthcare could lead to inappropriate or dangerous treatments, while the use of AI in financial services could lead to fraud and other financial crimes. To mitigate this risk, it is essential to establish clear regulations and oversight mechanisms around the use of AI, and to ensure that these regulations are enforced and updated regularly.\\\\n9. Misuse by malicious actors: AI systems can be used by malicious actors to carry out cyber attacks, spread disinformation, or engage in other forms of malicious activity. To mitigate this risk, it is essential to ensure that AI systems are designed with robust security and privacy controls, and that they are subject to regular security aud\"\\n  }\\n]'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9789399",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(\n",
    "    {\"inputs\": \"Large model inference is\", \"parameters\": {}, \"password\": \"12345\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd9042",
   "metadata": {},
   "source": [
    "## Clean up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d674b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_env",
   "language": "python",
   "name": "hf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
