{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77be7dda",
   "metadata": {},
   "source": [
    "## vllm Mixtral-8x7B-DPO-AWQ deployment guide\n",
    "\n",
    "In this tutorial, you will use vllm backend of Large Model Inference(LMI) DLC to deploy Mixtral-8x7B-DPO-AWQ and run inference with it.\n",
    "\n",
    "Please make sure the following permission granted before running the notebook:\n",
    "\n",
    "* SageMaker access\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc171a0",
   "metadata": {},
   "source": [
    "### Step 1: Let's bump up SageMaker and import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd49db4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install sagemaker --upgrade  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c2465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.djl_inference.model import DJLModel\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "session = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a817d0e",
   "metadata": {},
   "source": [
    "## Step 2: Start building SageMaker endpoint\n",
    "In this step, we will build SageMaker endpoint from scratch\n",
    "\n",
    "### Getting the container image URI (optional)\n",
    "\n",
    "Check out available images: [Large Model Inference available DLC](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92cee3-b7f2-4b93-9a1d-d916f03d8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a specific version of LMI image directly:\n",
    "# image_uri = \"763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c778f",
   "metadata": {},
   "source": [
    "### Create SageMaker model\n",
    "\n",
    "Here we are using [LMI PySDK](https://sagemaker.readthedocs.io/en/stable/frameworks/djl/using_djl.html) to create the model.\n",
    "\n",
    "Checkout more [configuration options](https://docs.djl.ai/docs/serving/serving/docs/lmi/deployment_guide/configurations.html#environment-variable-configurations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2967711-56a4-46b9-9bb6-78791ebd9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"TheBloke/Nous-Hermes-2-Mixtral-8x7B-DPO-AWQ\" # model will be download form Huggingface hub\n",
    "\n",
    "env = {\n",
    "    \"TENSOR_PARALLEL_DEGREE\": \"max\",          # use all GPUs on the instance\n",
    "    \"OPTION_ROLLING_BATCH\": \"vllm\",           # use vllm for rolling batching\n",
    "    \"OPTION_QUANTIZE\": \"awq\",\n",
    "    \"OPTION_MAX_MODEL_LEN\": \"8192\",\n",
    "}\n",
    "\n",
    "model = DJLModel(\n",
    "            model_id=model_id,\n",
    "            env=env,\n",
    "            role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98923d70-49d2-4811-b8a7-d061e610701a",
   "metadata": {},
   "source": [
    "### Create SageMaker endpoint\n",
    "\n",
    "You need to specify the instance to use and endpoint names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27a8df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.g4dn.12xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"lmi-model\")\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             endpoint_name=endpoint_name,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19004557",
   "metadata": {},
   "source": [
    "### Step 3: Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd192a22-3cda-4032-bdfd-0491e88cc068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_message=\"\"\n",
    "input_text = \"请解释一下AI\"\n",
    "\n",
    "prompt_template=f'''<|im_start|>system\n",
    "{system_message}<|im_end|>\n",
    "<|im_start|>user\n",
    "{input_text}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e426ba55-6cc3-4772-be77-0f99f29128e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_new_tokens\":128,\n",
    "    \"do_sample\":True,\n",
    "    \"temperature\":0.7,\n",
    "    \"top_p\":0.95,\n",
    "    \"top_k\":40,\n",
    "    \"repetition_penalty\":1.1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a450b46-8783-41b3-b2f4-1b1bb05e8613",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### None Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da82e0b-59bf-4514-9a9d-39885fa04cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(\n",
    "    {\n",
    "        \"inputs\": prompt_template, \n",
    "         \"parameters\": parameters\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c7d0b5-5ddb-40b3-848d-ce058b1a4b9e",
   "metadata": {},
   "source": [
    "#### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62229879-28d2-4ecc-b0cf-c366317e7823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533c5232-3764-47fe-b8fb-cb95b4a16d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_realtime_response_stream(sagemaker_runtime, endpoint_name, payload):\n",
    "    response_stream = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(payload), \n",
    "        ContentType=\"application/json\"\n",
    "    )\n",
    "    return response_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4d2e2-fa5b-4e13-925d-6c8bd41958ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"inputs\":  prompt_template,\n",
    "    \"parameters\": parameters,\n",
    "    \"stream\": True ## <-- to have response stream.\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289afdd-a048-40a1-be33-8a6628d6dc05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.LineIterator import LineIterator\n",
    "\n",
    "def print_response_stream(response_stream):\n",
    "    event_stream = response_stream.get('Body')\n",
    "    for line in LineIterator(event_stream):\n",
    "        print(line, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335da0ec-7f78-4815-981c-2294ad466e69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_stream = get_realtime_response_stream(smr_client, endpoint_name, payload)\n",
    "print_response_stream(response_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8352a-7eec-461d-b161-765a8a7220ba",
   "metadata": {},
   "source": [
    "## Clean up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9603928-b375-4d87-8c29-63b3cd59306a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session.delete_endpoint(endpoint_name)\n",
    "session.delete_endpoint_config(endpoint_name)\n",
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed0716-04ff-4863-a3cd-768db998cbc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
