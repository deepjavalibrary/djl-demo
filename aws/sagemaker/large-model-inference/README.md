## SageMaker sample notebook for LLM

In this section, we provide some sample instruction to use LMI container on SageMaker.

- [Bring-Your-Own-Container template](BYOC_template_with_LMI_solution.ipynb)
- [Standard model.py template](standard_template_with_LMI_solution.ipynb)
- [LMI PySDK template](pysdk_template_with_LMI_solution.ipynb)

For the list of LMI containers that is on DLC, please click [here](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers).

For the list of available BYOC containers, please clck [here](https://hub.docker.com/r/deepjavalibrary/djl-serving/tags).

For more information on LMI documentation on SageMaker, click [here](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-large-model-inference.html).

For all the serving.prorperties options you could set on DJLServing, click [here](https://docs.djl.ai/docs/serving/serving/docs/modes.html#servingproperties).
