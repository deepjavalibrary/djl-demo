{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a329f0",
   "metadata": {},
   "source": [
    "# BYOC instruction for using LMI container on SageMaker\n",
    "In this tutorial, you will bring your own container from docker hub to SageMaker and run inference with it.\n",
    "Please make sure the following permission granted before running the notebook:\n",
    "\n",
    "- ECR Push/Pull access\n",
    "- S3 bucket push access\n",
    "- SageMaker access\n",
    "- DynamoDB access\n",
    "\n",
    "## Step 1: Let's bump up SageMaker and import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "67fa3208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sagemaker boto3 awscli --upgrade  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ec9ac353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, serializers, deserializers\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71542f98",
   "metadata": {},
   "source": [
    "## Step 2 pull and push the docker from Docker hub to ECR repository\n",
    "\n",
    "*Note: Please make sure you have the permission in AWS credential to push to ECR repository*\n",
    "\n",
    "This process may take a while, depends on the container size and your network bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1efb852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ECR repository 125045733377.dkr.ecr.us-east-1.amazonaws.com/djlserving-byoc:latest\n",
      "Login Succeeded\n",
      "Start pulling container: deepjavalibrary/djl-serving:deepspeed-nightly\n",
      "deepspeed-nightly: Pulling from deepjavalibrary/djl-serving\n",
      "846c0b181fff: Pulling fs layer\n",
      "6599ec13b57f: Pulling fs layer\n",
      "e1426114a55b: Pulling fs layer\n",
      "f5a45ff4f0b5: Pulling fs layer\n",
      "51873ca0db79: Pulling fs layer\n",
      "8539eb40abca: Pulling fs layer\n",
      "f5a45ff4f0b5: Waiting\n",
      "b5e218b9a64b: Pulling fs layer\n",
      "d71da67a71de: Pulling fs layer\n",
      "8539eb40abca: Waiting\n",
      "4b4331e1e893: Pulling fs layer\n",
      "ba157caf65a0: Pulling fs layer\n",
      "4b4331e1e893: Waiting\n",
      "7dc2c379e8a4: Pulling fs layer\n",
      "57819aec952b: Pulling fs layer\n",
      "4a352577dbbb: Pulling fs layer\n",
      "7dc2c379e8a4: Waiting\n",
      "57819aec952b: Waiting\n",
      "9ac8cc841e71: Pulling fs layer\n",
      "b5e218b9a64b: Waiting\n",
      "4a352577dbbb: Waiting\n",
      "d71da67a71de: Waiting\n",
      "ed5e468826d6: Pulling fs layer\n",
      "c56c5861fc54: Pulling fs layer\n",
      "5e4c6f1cc111: Pulling fs layer\n",
      "f83e1b46ff02: Pulling fs layer\n",
      "ed5e468826d6: Waiting\n",
      "9fdb8c543f2d: Pulling fs layer\n",
      "c56c5861fc54: Waiting\n",
      "4641adf75814: Pulling fs layer\n",
      "9fdb8c543f2d: Waiting\n",
      "f83e1b46ff02: Waiting\n",
      "4641adf75814: Waiting\n",
      "846c0b181fff: Verifying Checksum\n",
      "846c0b181fff: Download complete\n",
      "6599ec13b57f: Verifying Checksum\n",
      "6599ec13b57f: Download complete\n",
      "f5a45ff4f0b5: Verifying Checksum\n",
      "f5a45ff4f0b5: Download complete\n",
      "51873ca0db79: Download complete\n",
      "b5e218b9a64b: Download complete\n",
      "d71da67a71de: Download complete\n",
      "4b4331e1e893: Verifying Checksum\n",
      "4b4331e1e893: Download complete\n",
      "e1426114a55b: Verifying Checksum\n",
      "e1426114a55b: Download complete\n",
      "846c0b181fff: Pull complete\n",
      "7dc2c379e8a4: Verifying Checksum\n",
      "7dc2c379e8a4: Download complete\n",
      "6599ec13b57f: Pull complete\n",
      "e1426114a55b: Pull complete\n",
      "f5a45ff4f0b5: Pull complete\n",
      "51873ca0db79: Pull complete\n",
      "57819aec952b: Verifying Checksum\n",
      "57819aec952b: Download complete\n",
      "4a352577dbbb: Download complete\n",
      "9ac8cc841e71: Verifying Checksum\n",
      "9ac8cc841e71: Download complete\n",
      "ed5e468826d6: Verifying Checksum\n",
      "ed5e468826d6: Download complete\n",
      "c56c5861fc54: Verifying Checksum\n",
      "c56c5861fc54: Download complete\n",
      "5e4c6f1cc111: Verifying Checksum\n",
      "5e4c6f1cc111: Download complete\n",
      "f83e1b46ff02: Verifying Checksum\n",
      "f83e1b46ff02: Download complete\n",
      "9fdb8c543f2d: Verifying Checksum\n",
      "9fdb8c543f2d: Download complete\n",
      "8539eb40abca: Verifying Checksum\n",
      "8539eb40abca: Download complete\n",
      "ba157caf65a0: Verifying Checksum\n",
      "8539eb40abca: Pull complete\n",
      "b5e218b9a64b: Pull complete\n",
      "d71da67a71de: Pull complete\n",
      "4b4331e1e893: Pull complete\n",
      "4641adf75814: Verifying Checksum\n",
      "4641adf75814: Download complete\n",
      "ba157caf65a0: Pull complete\n",
      "7dc2c379e8a4: Pull complete\n",
      "57819aec952b: Pull complete\n",
      "4a352577dbbb: Pull complete\n",
      "9ac8cc841e71: Pull complete\n",
      "ed5e468826d6: Pull complete\n",
      "c56c5861fc54: Pull complete\n",
      "5e4c6f1cc111: Pull complete\n",
      "f83e1b46ff02: Pull complete\n",
      "9fdb8c543f2d: Pull complete\n",
      "4641adf75814: Pull complete\n",
      "Digest: sha256:3e6d31ed5bb20a54f90a094ac88acdceeb6b33ba43ead4c923890344d7db31b2\n",
      "Status: Downloaded newer image for deepjavalibrary/djl-serving:deepspeed-nightly\n",
      "docker.io/deepjavalibrary/djl-serving:deepspeed-nightly\n",
      "The push refers to repository [125045733377.dkr.ecr.us-east-1.amazonaws.com/djlserving-byoc]\n",
      "6bea989c944b: Preparing\n",
      "4adfae1fd883: Preparing\n",
      "08100542073d: Preparing\n",
      "cf8673923c4c: Preparing\n",
      "2c64034719ca: Preparing\n",
      "bbf36c25fd98: Preparing\n",
      "2ab0a582566a: Preparing\n",
      "a550e7ba465a: Preparing\n",
      "9f47ad0160c8: Preparing\n",
      "822919f77330: Preparing\n",
      "a2654928891a: Preparing\n",
      "cdedc6c127e1: Preparing\n",
      "ac85f70f8859: Preparing\n",
      "590f3ac20d28: Preparing\n",
      "c263f12cd4e6: Preparing\n",
      "99832d04a153: Preparing\n",
      "a5981ed7a378: Preparing\n",
      "250519a2f830: Preparing\n",
      "6cadbde53f94: Preparing\n",
      "0002c93bdb37: Preparing\n",
      "bbf36c25fd98: Waiting\n",
      "a5981ed7a378: Waiting\n",
      "cdedc6c127e1: Waiting\n",
      "2ab0a582566a: Waiting\n",
      "9f47ad0160c8: Waiting\n",
      "250519a2f830: Waiting\n",
      "a550e7ba465a: Waiting\n",
      "ac85f70f8859: Waiting\n",
      "822919f77330: Waiting\n",
      "6cadbde53f94: Waiting\n",
      "590f3ac20d28: Waiting\n",
      "c263f12cd4e6: Waiting\n",
      "99832d04a153: Waiting\n",
      "0002c93bdb37: Waiting\n",
      "a2654928891a: Waiting\n",
      "cf8673923c4c: Pushed\n",
      "4adfae1fd883: Pushed\n",
      "08100542073d: Pushed\n",
      "2c64034719ca: Pushed\n",
      "2ab0a582566a: Pushed\n",
      "bbf36c25fd98: Pushed\n",
      "a550e7ba465a: Pushed\n",
      "822919f77330: Pushed\n",
      "cdedc6c127e1: Pushed\n",
      "ac85f70f8859: Pushed\n",
      "590f3ac20d28: Pushed\n",
      "99832d04a153: Pushed\n",
      "a5981ed7a378: Pushed\n",
      "250519a2f830: Pushed\n",
      "6cadbde53f94: Pushed\n",
      "0002c93bdb37: Pushed\n",
      "c263f12cd4e6: Pushed\n",
      "9f47ad0160c8: Pushed\n",
      "a2654928891a: Pushed\n",
      "6bea989c944b: Pushed\n",
      "latest: digest: sha256:3e6d31ed5bb20a54f90a094ac88acdceeb6b33ba43ead4c923890344d7db31b2 size: 4509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# The name of our container\n",
    "repo_name=djlserving-byoc\n",
    "# Target container\n",
    "target_container=\"deepjavalibrary/djl-serving:deepspeed-nightly\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${repo_name}:latest\"\n",
    "echo \"Creating ECR repository ${fullname}\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${repo_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${repo_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin \"${account}.dkr.ecr.${region}.amazonaws.com\"\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "echo \"Start pulling container: ${target_container}\"\n",
    "\n",
    "docker pull ${target_container}\n",
    "docker tag ${target_container} ${fullname}\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81deac79",
   "metadata": {},
   "source": [
    "## Step 3: Start preparing model artifacts\n",
    "In LMI contianer, we expect some artifacts to help setting up the model\n",
    "- serving.properties (required): Defines the model server settings\n",
    "- model.py (optional): A python file to define the core inference logic\n",
    "- requirements.txt (optional): Any additional pip wheel need to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b011bf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.tensor_parallel_degree=1\n",
    "option.predict_timeout=1200\n",
    "option.model_id=cerebras/Cerebras-GPT-1.3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "19d6798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "from djl_python import Input, Output\n",
    "import torch\n",
    "import logging\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from djl_python.streaming_utils import StreamingUtils\n",
    "from paginator import DDBPaginator\n",
    "import uuid\n",
    "\n",
    "\n",
    "def load_model(properties):\n",
    "    model_location = properties['model_dir']\n",
    "    if \"model_id\" in properties:\n",
    "        model_location = properties['model_id']\n",
    "    logging.info(f\"Loading model in {model_location}\")\n",
    "    device = \"cuda:0\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_location, low_cpu_mem_usage=True, torch_dtype=torch.float16).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_location)\n",
    "    stream_generator = StreamingUtils.get_stream_generator(\"Accelerate\")\n",
    "    return model, tokenizer, stream_generator\n",
    "\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "stream_generator = None\n",
    "paginator = None\n",
    "\n",
    "def separate_inference(session_id, inputs):\n",
    "    prompt = inputs[\"prompt\"]\n",
    "    length = inputs[\"max_new_tokens\"]\n",
    "    generate_kwargs = dict(max_new_tokens=length, do_sample=True)\n",
    "    generator = stream_generator(model, tokenizer, prompt, **generate_kwargs)\n",
    "    generated = \"\"\n",
    "    iterator = 0\n",
    "    for text in generator:\n",
    "        generated += text[0]\n",
    "        if iterator == 5:\n",
    "            paginator.add_cache(session_id, generated)\n",
    "            iterator = 0\n",
    "        iterator += 1\n",
    "    paginator.add_cache(session_id, generated + \"<eos>\")\n",
    "\n",
    "\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    global model, tokenizer, stream_generator, paginator\n",
    "    if not model:\n",
    "        model, tokenizer, stream_generator = load_model(inputs.get_properties())\n",
    "        paginator = DDBPaginator(\"test_DB_Qing\")\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        # Model server makes an empty call to warmup the model on startup\n",
    "        return None\n",
    "    session_id = str(uuid.uuid4())\n",
    "    return Output().add({\"session_id\": session_id}).finalize(separate_inference, session_id, inputs.get_as_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "02e53e8c-9b3b-47a1-9afc-d1c8621269e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing paginator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile paginator.py\n",
    "import boto3\n",
    "import logging\n",
    "\n",
    "\n",
    "class DDBPaginator:\n",
    "    DEFAULT_KEY_NAME = \"cache_id\"\n",
    "\n",
    "    def __init__(self, db_name):\n",
    "        self.db_name = db_name\n",
    "        self.ddb_client = boto3.client('dynamodb')\n",
    "        try:\n",
    "            self.ddb_client.describe_table(TableName=db_name)\n",
    "        except self.ddb_client.exceptions.ResourceNotFoundException:\n",
    "            logging.info(f\"Table {db_name} not found\")\n",
    "            self.ddb_client.create_table(TableName=db_name,\n",
    "                                         AttributeDefinitions=[{\n",
    "                                             'AttributeName': self.DEFAULT_KEY_NAME,\n",
    "                                             'AttributeType': 'S'\n",
    "                                         }, ],\n",
    "                                         KeySchema=[\n",
    "                                             {\n",
    "                                                 'AttributeName': self.DEFAULT_KEY_NAME,\n",
    "                                                 'KeyType': 'HASH'\n",
    "                                             }],\n",
    "                                         BillingMode='PAY_PER_REQUEST'\n",
    "                                         )\n",
    "\n",
    "    def add_cache(self, session_id, content):\n",
    "        return self.ddb_client.put_item(TableName=self.db_name,\n",
    "                                        Item={self.DEFAULT_KEY_NAME: {\"S\": session_id}, \"content\": {\"S\": content}})\n",
    "\n",
    "    def get_cache(self, session_id):\n",
    "        result = self.ddb_client.get_item(TableName=self.db_name, Key={self.DEFAULT_KEY_NAME: {\"S\": session_id}})\n",
    "        return result['Item']['content']['S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e8b50a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "boto3\n",
    "transformers==4.27.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b0142973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mymodel/\n",
      "mymodel/model.py\n",
      "mymodel/serving.properties\n",
      "mymodel/paginator.py\n",
      "mymodel/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir mymodel\n",
    "mv serving.properties mymodel/\n",
    "mv model.py mymodel/\n",
    "mv paginator.py mymodel/\n",
    "mv requirements.txt mymodel/\n",
    "tar czvf mymodel.tar.gz mymodel/\n",
    "rm -rf mymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58cf33",
   "metadata": {},
   "source": [
    "## Step 4: Start building SageMaker endpoint\n",
    "In this step, we will build SageMaker endpoint from scratch\n",
    "\n",
    "### 4.1 Upload artifact on S3 and create SageMaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "38b1e5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-east-1-125045733377/large-model-lmi/code/mymodel.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_prefix = \"large-model-lmi/code\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "code_artifact = sess.upload_data(\"mymodel.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")\n",
    "\n",
    "repo_name=\"djlserving-byoc\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{repo_name}:latest\"\n",
    "env = {\"HUGGINGFACE_HUB_CACHE\": \"/tmp\", \"TRANSFORMERS_CACHE\": \"/tmp\"}\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=code_artifact, env=env, role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f39f6",
   "metadata": {},
   "source": [
    "### 4.2 Create SageMaker endpoint\n",
    "\n",
    "You need to specify the instance to use and endpoint names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8e0e61cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "instance_type = \"ml.g5.2xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"lmi-model\")\n",
    "\n",
    "model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             endpoint_name=endpoint_name,\n",
    "             # container_startup_health_check_timeout=3600\n",
    "            )\n",
    "\n",
    "# our requests and responses will be in json format so we specify the serializer and the deserializer\n",
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializer=deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63ee65",
   "metadata": {},
   "source": [
    "## Step 5: Test and benchmark the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2bcef095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "A:\n",
      "\n",
      "You can use the built-in bubble_search module.\n",
      "from bubble_search import *\n",
      "\n",
      "def bubble_search(text):\n",
      "    \"\"\"\n",
      "    Search for a word in a text.\n",
      "\n",
      "    :param text: The text to search for.\n",
      "    :return: The word found.\n",
      "    \"\"\"\n",
      "    word = text.split()\n",
      "    word = word[0]\n",
      "    word = word.lower()\n",
      "    word = word.replace(' ', '')\n",
      "    word = word.replace(' ', '')\n",
      "    word = word.replace(' ', '')\n",
      "    word = word.replace(' ', '')\n",
      "    word = word.replace(' ', '')\n",
      "    word = word.replace(' ', '')\n",
      "    word = word.replace(' ', '')\n",
      "    word = word.replace(' ', '')\n",
      "    word = word.replace(' ', '')\n",
      "    word = word.replace(' ', '')\n",
      "    word = word.replace(' ', '')\n",
      "<eos>"
     ]
    }
   ],
   "source": [
    "import time\n",
    "session_id = predictor.predict({\"prompt\": [\"Write a code that could do bubble search in python\"], \"max_new_tokens\": 256})\n",
    "def get_stream(session_id):\n",
    "        ddb_client = boto3.client('dynamodb')\n",
    "        prev = 0\n",
    "        while True:\n",
    "            result = ddb_client.get_item(TableName=\"test_DB_Qing\", Key={\"cache_id\": {\"S\": session_id}})\n",
    "            if 'Item' in result:\n",
    "                text = result['Item']['content']['S']\n",
    "                print(text[prev:], end='')\n",
    "                prev = len(text)\n",
    "                if text.endswith('<eos>'):\n",
    "                    break\n",
    "            time.sleep(0.1)\n",
    "get_stream(session_id['session_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd9042",
   "metadata": {},
   "source": [
    "## Clean up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3d674b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598759b4-4ef0-4a1f-9b3c-c988c8a120c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
