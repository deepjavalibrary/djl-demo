{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a329f0",
   "metadata": {},
   "source": [
    "# BYOC instruction for using LMI container on SageMaker\n",
    "In this tutorial, you will bring your own container from docker hub to SageMaker and run inference with it.\n",
    "Please make sure the following permission granted before running the notebook:\n",
    "\n",
    "- ECR Push/Pull access\n",
    "- S3 bucket push access\n",
    "- SageMaker access\n",
    "- DynamoDB access (create DB and query)\n",
    "\n",
    "If you plan to do step 6, we also need to have lambda and API-gateway permission.\n",
    "\n",
    "- AWSLambda access (Create lambda function)\n",
    "- IAM access (Create role, delete role)\n",
    "- APIGateway (Creation, deletion)\n",
    "\n",
    "## Step 1: Let's bump up SageMaker and import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67fa3208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sagemaker boto3 awscli --upgrade  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9ac353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, serializers, deserializers\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71542f98",
   "metadata": {},
   "source": [
    "## Step 2 pull and push the docker from Docker hub to ECR repository\n",
    "\n",
    "*Note: Please make sure you have the permission in AWS credential to push to ECR repository*\n",
    "\n",
    "This process may take a while, depends on the container size and your network bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1efb852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ECR repository 125045733377.dkr.ecr.us-east-1.amazonaws.com/djlserving-byoc:latest\n",
      "Login Succeeded\n",
      "Start pulling container: deepjavalibrary/djl-serving:deepspeed-nightly\n",
      "deepspeed-nightly: Pulling from deepjavalibrary/djl-serving\n",
      "846c0b181fff: Pulling fs layer\n",
      "6599ec13b57f: Pulling fs layer\n",
      "e1426114a55b: Pulling fs layer\n",
      "f5a45ff4f0b5: Pulling fs layer\n",
      "51873ca0db79: Pulling fs layer\n",
      "8539eb40abca: Pulling fs layer\n",
      "f5a45ff4f0b5: Waiting\n",
      "b5e218b9a64b: Pulling fs layer\n",
      "d71da67a71de: Pulling fs layer\n",
      "8539eb40abca: Waiting\n",
      "4b4331e1e893: Pulling fs layer\n",
      "ba157caf65a0: Pulling fs layer\n",
      "4b4331e1e893: Waiting\n",
      "7dc2c379e8a4: Pulling fs layer\n",
      "57819aec952b: Pulling fs layer\n",
      "4a352577dbbb: Pulling fs layer\n",
      "7dc2c379e8a4: Waiting\n",
      "57819aec952b: Waiting\n",
      "9ac8cc841e71: Pulling fs layer\n",
      "b5e218b9a64b: Waiting\n",
      "4a352577dbbb: Waiting\n",
      "d71da67a71de: Waiting\n",
      "ed5e468826d6: Pulling fs layer\n",
      "c56c5861fc54: Pulling fs layer\n",
      "5e4c6f1cc111: Pulling fs layer\n",
      "f83e1b46ff02: Pulling fs layer\n",
      "ed5e468826d6: Waiting\n",
      "9fdb8c543f2d: Pulling fs layer\n",
      "c56c5861fc54: Waiting\n",
      "4641adf75814: Pulling fs layer\n",
      "9fdb8c543f2d: Waiting\n",
      "f83e1b46ff02: Waiting\n",
      "4641adf75814: Waiting\n",
      "846c0b181fff: Verifying Checksum\n",
      "846c0b181fff: Download complete\n",
      "6599ec13b57f: Verifying Checksum\n",
      "6599ec13b57f: Download complete\n",
      "f5a45ff4f0b5: Verifying Checksum\n",
      "f5a45ff4f0b5: Download complete\n",
      "51873ca0db79: Download complete\n",
      "b5e218b9a64b: Download complete\n",
      "d71da67a71de: Download complete\n",
      "4b4331e1e893: Verifying Checksum\n",
      "4b4331e1e893: Download complete\n",
      "e1426114a55b: Verifying Checksum\n",
      "e1426114a55b: Download complete\n",
      "846c0b181fff: Pull complete\n",
      "7dc2c379e8a4: Verifying Checksum\n",
      "7dc2c379e8a4: Download complete\n",
      "6599ec13b57f: Pull complete\n",
      "e1426114a55b: Pull complete\n",
      "f5a45ff4f0b5: Pull complete\n",
      "51873ca0db79: Pull complete\n",
      "57819aec952b: Verifying Checksum\n",
      "57819aec952b: Download complete\n",
      "4a352577dbbb: Download complete\n",
      "9ac8cc841e71: Verifying Checksum\n",
      "9ac8cc841e71: Download complete\n",
      "ed5e468826d6: Verifying Checksum\n",
      "ed5e468826d6: Download complete\n",
      "c56c5861fc54: Verifying Checksum\n",
      "c56c5861fc54: Download complete\n",
      "5e4c6f1cc111: Verifying Checksum\n",
      "5e4c6f1cc111: Download complete\n",
      "f83e1b46ff02: Verifying Checksum\n",
      "f83e1b46ff02: Download complete\n",
      "9fdb8c543f2d: Verifying Checksum\n",
      "9fdb8c543f2d: Download complete\n",
      "8539eb40abca: Verifying Checksum\n",
      "8539eb40abca: Download complete\n",
      "ba157caf65a0: Verifying Checksum\n",
      "8539eb40abca: Pull complete\n",
      "b5e218b9a64b: Pull complete\n",
      "d71da67a71de: Pull complete\n",
      "4b4331e1e893: Pull complete\n",
      "4641adf75814: Verifying Checksum\n",
      "4641adf75814: Download complete\n",
      "ba157caf65a0: Pull complete\n",
      "7dc2c379e8a4: Pull complete\n",
      "57819aec952b: Pull complete\n",
      "4a352577dbbb: Pull complete\n",
      "9ac8cc841e71: Pull complete\n",
      "ed5e468826d6: Pull complete\n",
      "c56c5861fc54: Pull complete\n",
      "5e4c6f1cc111: Pull complete\n",
      "f83e1b46ff02: Pull complete\n",
      "9fdb8c543f2d: Pull complete\n",
      "4641adf75814: Pull complete\n",
      "Digest: sha256:3e6d31ed5bb20a54f90a094ac88acdceeb6b33ba43ead4c923890344d7db31b2\n",
      "Status: Downloaded newer image for deepjavalibrary/djl-serving:deepspeed-nightly\n",
      "docker.io/deepjavalibrary/djl-serving:deepspeed-nightly\n",
      "The push refers to repository [125045733377.dkr.ecr.us-east-1.amazonaws.com/djlserving-byoc]\n",
      "6bea989c944b: Preparing\n",
      "4adfae1fd883: Preparing\n",
      "08100542073d: Preparing\n",
      "cf8673923c4c: Preparing\n",
      "2c64034719ca: Preparing\n",
      "bbf36c25fd98: Preparing\n",
      "2ab0a582566a: Preparing\n",
      "a550e7ba465a: Preparing\n",
      "9f47ad0160c8: Preparing\n",
      "822919f77330: Preparing\n",
      "a2654928891a: Preparing\n",
      "cdedc6c127e1: Preparing\n",
      "ac85f70f8859: Preparing\n",
      "590f3ac20d28: Preparing\n",
      "c263f12cd4e6: Preparing\n",
      "99832d04a153: Preparing\n",
      "a5981ed7a378: Preparing\n",
      "250519a2f830: Preparing\n",
      "6cadbde53f94: Preparing\n",
      "0002c93bdb37: Preparing\n",
      "bbf36c25fd98: Waiting\n",
      "a5981ed7a378: Waiting\n",
      "cdedc6c127e1: Waiting\n",
      "2ab0a582566a: Waiting\n",
      "9f47ad0160c8: Waiting\n",
      "250519a2f830: Waiting\n",
      "a550e7ba465a: Waiting\n",
      "ac85f70f8859: Waiting\n",
      "822919f77330: Waiting\n",
      "6cadbde53f94: Waiting\n",
      "590f3ac20d28: Waiting\n",
      "c263f12cd4e6: Waiting\n",
      "99832d04a153: Waiting\n",
      "0002c93bdb37: Waiting\n",
      "a2654928891a: Waiting\n",
      "cf8673923c4c: Pushed\n",
      "4adfae1fd883: Pushed\n",
      "08100542073d: Pushed\n",
      "2c64034719ca: Pushed\n",
      "2ab0a582566a: Pushed\n",
      "bbf36c25fd98: Pushed\n",
      "a550e7ba465a: Pushed\n",
      "822919f77330: Pushed\n",
      "cdedc6c127e1: Pushed\n",
      "ac85f70f8859: Pushed\n",
      "590f3ac20d28: Pushed\n",
      "99832d04a153: Pushed\n",
      "a5981ed7a378: Pushed\n",
      "250519a2f830: Pushed\n",
      "6cadbde53f94: Pushed\n",
      "0002c93bdb37: Pushed\n",
      "c263f12cd4e6: Pushed\n",
      "9f47ad0160c8: Pushed\n",
      "a2654928891a: Pushed\n",
      "6bea989c944b: Pushed\n",
      "latest: digest: sha256:3e6d31ed5bb20a54f90a094ac88acdceeb6b33ba43ead4c923890344d7db31b2 size: 4509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# The name of our container\n",
    "repo_name=djlserving-byoc\n",
    "# Target container\n",
    "target_container=\"deepjavalibrary/djl-serving:deepspeed-nightly\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${repo_name}:latest\"\n",
    "echo \"Creating ECR repository ${fullname}\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${repo_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${repo_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin \"${account}.dkr.ecr.${region}.amazonaws.com\"\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "echo \"Start pulling container: ${target_container}\"\n",
    "\n",
    "docker pull ${target_container}\n",
    "docker tag ${target_container} ${fullname}\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81deac79",
   "metadata": {},
   "source": [
    "## Step 3: Start preparing model artifacts\n",
    "In LMI contianer, we expect some artifacts to help setting up the model\n",
    "- serving.properties (required): Defines the model server settings\n",
    "- model.py (optional): A python file to define the core inference logic\n",
    "- requirements.txt (optional): Any additional pip wheel need to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b011bf5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.tensor_parallel_degree=1\n",
    "option.predict_timeout=1200\n",
    "option.model_id=cerebras/Cerebras-GPT-1.3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d6798b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "from djl_python import Input, Output\n",
    "import torch\n",
    "import logging\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from djl_python.streaming_utils import StreamingUtils\n",
    "from paginator import DDBPaginator\n",
    "import uuid\n",
    "\n",
    "\n",
    "def load_model(properties):\n",
    "    model_location = properties['model_dir']\n",
    "    if \"model_id\" in properties:\n",
    "        model_location = properties['model_id']\n",
    "    logging.info(f\"Loading model in {model_location}\")\n",
    "    device = \"cuda:0\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_location, low_cpu_mem_usage=True, torch_dtype=torch.float16).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_location)\n",
    "    stream_generator = StreamingUtils.get_stream_generator(\"Accelerate\")\n",
    "    return model, tokenizer, stream_generator\n",
    "\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "stream_generator = None\n",
    "paginator = None\n",
    "\n",
    "def separate_inference(session_id, inputs):\n",
    "    prompt = inputs[\"prompt\"]\n",
    "    length = inputs[\"max_new_tokens\"]\n",
    "    generate_kwargs = dict(max_new_tokens=length, do_sample=True)\n",
    "    generator = stream_generator(model, tokenizer, prompt, **generate_kwargs)\n",
    "    generated = \"\"\n",
    "    iterator = 0\n",
    "    for text in generator:\n",
    "        generated += text[0]\n",
    "        if iterator == 5:\n",
    "            paginator.add_cache(session_id, generated)\n",
    "            iterator = 0\n",
    "        iterator += 1\n",
    "    paginator.add_cache(session_id, generated + \"<eos>\")\n",
    "\n",
    "\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    global model, tokenizer, stream_generator, paginator\n",
    "    if not model:\n",
    "        model, tokenizer, stream_generator = load_model(inputs.get_properties())\n",
    "        paginator = DDBPaginator(\"test_DB_Qing\")\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        # Model server makes an empty call to warmup the model on startup\n",
    "        return None\n",
    "    session_id = str(uuid.uuid4())\n",
    "    return Output().add({\"session_id\": session_id}).finalize(separate_inference, session_id, inputs.get_as_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02e53e8c-9b3b-47a1-9afc-d1c8621269e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing paginator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile paginator.py\n",
    "import boto3\n",
    "import logging\n",
    "\n",
    "\n",
    "class DDBPaginator:\n",
    "    DEFAULT_KEY_NAME = \"cache_id\"\n",
    "\n",
    "    def __init__(self, db_name):\n",
    "        self.db_name = db_name\n",
    "        self.ddb_client = boto3.client('dynamodb')\n",
    "        try:\n",
    "            self.ddb_client.describe_table(TableName=db_name)\n",
    "        except self.ddb_client.exceptions.ResourceNotFoundException:\n",
    "            logging.info(f\"Table {db_name} not found\")\n",
    "            self.ddb_client.create_table(TableName=db_name,\n",
    "                                         AttributeDefinitions=[{\n",
    "                                             'AttributeName': self.DEFAULT_KEY_NAME,\n",
    "                                             'AttributeType': 'S'\n",
    "                                         }, ],\n",
    "                                         KeySchema=[\n",
    "                                             {\n",
    "                                                 'AttributeName': self.DEFAULT_KEY_NAME,\n",
    "                                                 'KeyType': 'HASH'\n",
    "                                             }],\n",
    "                                         BillingMode='PAY_PER_REQUEST'\n",
    "                                         )\n",
    "            waiter = self.ddb_client.get_waiter('table_exists')\n",
    "            waiter.wait(TableName=db_name, WaiterConfig={'Delay': 1})\n",
    "\n",
    "    def add_cache(self, session_id, content):\n",
    "        return self.ddb_client.put_item(TableName=self.db_name,\n",
    "                                        Item={self.DEFAULT_KEY_NAME: {\"S\": session_id}, \"content\": {\"S\": content}})\n",
    "\n",
    "    def get_cache(self, session_id):\n",
    "        result = self.ddb_client.get_item(TableName=self.db_name, Key={self.DEFAULT_KEY_NAME: {\"S\": session_id}})\n",
    "        return result['Item']['content']['S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b50a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "boto3\n",
    "transformers==4.27.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0142973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mymodel/\n",
      "mymodel/model.py\n",
      "mymodel/serving.properties\n",
      "mymodel/paginator.py\n",
      "mymodel/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir mymodel\n",
    "mv serving.properties mymodel/\n",
    "mv model.py mymodel/\n",
    "mv paginator.py mymodel/\n",
    "mv requirements.txt mymodel/\n",
    "tar czvf mymodel.tar.gz mymodel/\n",
    "rm -rf mymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58cf33",
   "metadata": {},
   "source": [
    "## Step 4: Start building SageMaker endpoint\n",
    "In this step, we will build SageMaker endpoint from scratch\n",
    "\n",
    "### 4.1 Upload artifact on S3 and create SageMaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b1e5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-east-1-125045733377/large-model-lmi/code/mymodel.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_prefix = \"large-model-lmi/code\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "code_artifact = sess.upload_data(\"mymodel.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")\n",
    "\n",
    "repo_name=\"djlserving-byoc\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{repo_name}:latest\"\n",
    "env = {\"HUGGINGFACE_HUB_CACHE\": \"/tmp\", \"TRANSFORMERS_CACHE\": \"/tmp\"}\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=code_artifact, env=env, role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f39f6",
   "metadata": {},
   "source": [
    "### 4.2 Create SageMaker endpoint\n",
    "\n",
    "You need to specify the instance to use and endpoint names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e0e61cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "instance_type = \"ml.g5.2xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"lmi-model\")\n",
    "\n",
    "model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             endpoint_name=endpoint_name,\n",
    "             # container_startup_health_check_timeout=3600\n",
    "            )\n",
    "\n",
    "# our requests and responses will be in json format so we specify the serializer and the deserializer\n",
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializer=deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63ee65",
   "metadata": {},
   "source": [
    "## Step 5: Test and benchmark the inference\n",
    "\n",
    "In here, we use a SageMaker endpoint + DDB simple fetcher to get the response result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bcef095",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "A:\n",
      "\n",
      "You can use the following code to sort a list of tuples:\n",
      "def bubbleSort(lst):\n",
      "    \"\"\"Sort a list of tuples in ascending order.\"\"\"\n",
      "    for i in lst:\n",
      "        yield i\n",
      "\n",
      "lst = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "def bubbleSort(lst):\n",
      "    \"\"\"Sort a list of tuples in descending order.\"\"\"\n",
      "    for i in lst:\n",
      "        yield i\n",
      "\n",
      "lst = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "lst.sort()\n",
      "\n",
      "Output:\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4<eos>"
     ]
    }
   ],
   "source": [
    "import time\n",
    "session_id = predictor.predict({\"prompt\": [\"write a bubble sort algorithm in python\"], \"max_new_tokens\": 512})\n",
    "def get_stream(session_id):\n",
    "        ddb_client = boto3.client('dynamodb')\n",
    "        prev = 0\n",
    "        while True:\n",
    "            result = ddb_client.get_item(TableName=\"test_DB_Qing\", Key={\"cache_id\": {\"S\": session_id}})\n",
    "            if 'Item' in result:\n",
    "                text = result['Item']['content']['S']\n",
    "                print(text[prev:], end='')\n",
    "                prev = len(text)\n",
    "                if text.endswith('<eos>'):\n",
    "                    break\n",
    "            time.sleep(0.1)\n",
    "get_stream(session_id['session_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da05cbc-af43-4b36-bcff-0c6132f50b72",
   "metadata": {},
   "source": [
    "## Step 6: Make this as a single endpoint service\n",
    "\n",
    "in the previous example, we just demoed how to create an endpoint and use CLI to complete inference. Now, let's build a real-world application using Lambda and API-Gateway. Here we used an open-sourced toolkit by AWS called [Chalice](https://github.com/aws/chalice). It combines most commonly used Lambda/DynamoDB/APIGateway functions to deploy the stack easily.\n",
    "\n",
    "Chalice requires 4 major components:\n",
    "\n",
    "- `app.py`: Place to define your lambda function and related services\n",
    "- `requirements.txt`: pip wheel needed to drive the applicaiton\n",
    "- `.chalice/config.json`: a json file defines the generation logic and deployment stage\n",
    "- `.chalice/policy-<stage>.json`: a json file defines the policy that needs to attach to an IAM role of Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb0d9078-d909-46fc-a452-ed54f35f62ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chalice requests --upgrade  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3cb795a3-bbec-42db-bf27-eae1607aa2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import serializers, deserializers\n",
    "from chalice import Chalice\n",
    "\n",
    "app = Chalice(app_name='stream_endpoint')\n",
    "TABLE_NAME=\"test_DB\"\n",
    "SM_ENDPOINT_NAME=\"lmi-model-deployment\"\n",
    "sm_predictor = None\n",
    "\n",
    "@app.route('/query', methods=['POST'])\n",
    "def run_inference():\n",
    "    body = app.current_request.json_body\n",
    "    if \"session_id\" in body:\n",
    "        return ddb_fetcher(body[\"session_id\"])\n",
    "    elif \"prompt\" in body:\n",
    "        return get_sm_predictor().predict(body)\n",
    "    else:\n",
    "        return {\"result\" : \"Error!\", \"_debug\": body}\n",
    "\n",
    "def ddb_fetcher(session_id):\n",
    "    ddb_client = boto3.client('dynamodb')\n",
    "    result = ddb_client.get_item(TableName=TABLE_NAME, Key={\"cache_id\": {\"S\": session_id}})\n",
    "    if 'Item' in result:\n",
    "        return {\"result\" : result['Item']['content']['S']}\n",
    "    return {\"result\": \"\", \"_debug\": result}\n",
    "\n",
    "\n",
    "def get_sm_predictor():\n",
    "    global sm_predictor\n",
    "    if sm_predictor is None:\n",
    "        sess = sagemaker.session.Session()\n",
    "        sm_predictor = sagemaker.Predictor(\n",
    "            endpoint_name=SM_ENDPOINT_NAME,\n",
    "            sagemaker_session=sess,\n",
    "            serializer=serializers.JSONSerializer(),\n",
    "            deserializer=deserializers.JSONDeserializer(),\n",
    "        )\n",
    "    return sm_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ddbc81a-10c1-4435-9f64-1d5619ec2fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "boto3\n",
    "sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "deb6fe20-62a4-44b8-8234-c26744146022",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.json\n",
    "{\n",
    "  \"version\": \"2.0\",\n",
    "  \"app_name\": \"stream_endpoint\",\n",
    "  \"stages\": {\n",
    "    \"dev\": {\n",
    "      \"autogen_policy\": false,\n",
    "      \"api_gateway_stage\": \"api\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eeb7f8f4-6773-42ec-8805-f613f0b9a1ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing policy-dev.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile policy-dev.json\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Action\": [\n",
    "        \"logs:CreateLogGroup\",\n",
    "        \"logs:CreateLogStream\",\n",
    "        \"logs:PutLogEvents\"\n",
    "      ],\n",
    "      \"Resource\": \"arn:aws:logs:*:*:*\",\n",
    "      \"Effect\": \"Allow\"\n",
    "    },\n",
    "    {\n",
    "      \"Action\": [\n",
    "        \"dynamodb:GetItem\",\n",
    "        \"dynamodb:Scan\",\n",
    "        \"dynamodb:Query\"\n",
    "      ],\n",
    "      \"Resource\": [\n",
    "        \"arn:aws:dynamodb:*:*:table/test_DB*\"\n",
    "      ],\n",
    "      \"Effect\": \"Allow\"\n",
    "    },\n",
    "    {\n",
    "      \"Action\": [\n",
    "        \"sagemaker:ListEndpoints\",\n",
    "        \"sagemaker:InvokeEndpoint\"\n",
    "      ],\n",
    "      \"Resource\": [\n",
    "        \"arn:aws:sagemaker:*:*:endpoint/lmi*\"\n",
    "      ],\n",
    "      \"Effect\": \"Allow\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd4a5f-da1a-4e53-97b8-0dbfd40d7ba4",
   "metadata": {},
   "source": [
    "Now, let's do deployment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb685733-646b-47bf-bff2-c72cd22eb1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating deployment package.\n",
      "Reusing existing deployment package.\n",
      "Updating policy for IAM role: stream_endpoint-dev-api_handler\n",
      "Creating lambda function: stream_endpoint-dev\n",
      "Creating Rest API\n",
      "Resources deployed:\n",
      "  - Lambda ARN: arn:aws:lambda:us-east-1:125045733377:function:stream_endpoint-dev\n",
      "  - Rest API URL: https://fdtazsc92c.execute-api.us-east-1.amazonaws.com/api/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p deployment/.chalice\n",
    "mv app.py deployment/\n",
    "mv requirements.txt deployment/\n",
    "mv policy-dev.json deployment/.chalice/\n",
    "mv config.json deployment/.chalice/\n",
    "cd deployment/\n",
    "chalice deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd9042",
   "metadata": {},
   "source": [
    "## Clean up the environment\n",
    "\n",
    "If you have lambda and API gateway environment, do the following to clean up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74d059e2-7f70-4908-9eed-ae00f12938de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Rest API: fdtazsc92c\n",
      "Deleting function: arn:aws:lambda:us-east-1:125045733377:function:stream_endpoint-dev\n",
      "Deleting IAM role: stream_endpoint-dev-api_handler\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd deployment/\n",
    "chalice delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d297acb-ef3c-4610-985e-a638a7694a06",
   "metadata": {},
   "source": [
    "Clean up the SageMaker endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d674b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598759b4-4ef0-4a1f-9b3c-c988c8a120c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
