{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a329f0",
   "metadata": {},
   "source": [
    "# BYOC instruction for using LMI container on SageMaker\n",
    "In this tutorial, you will bring your own container from docker hub to SageMaker and run inference with it.\n",
    "Please make sure the following permission granted before running the notebook:\n",
    "\n",
    "- ECR Push/Pull access\n",
    "- S3 bucket push access\n",
    "- SageMaker access\n",
    "- DynamoDB access (create DB and query)\n",
    "\n",
    "If you plan to do step 6, we also need to have lambda and API-gateway permission.\n",
    "\n",
    "- AWSLambda access (Create lambda function)\n",
    "- IAM access (Create role, delete role)\n",
    "- APIGateway (Creation, deletion)\n",
    "\n",
    "## Step 1: Let's bump up SageMaker and import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa3208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install sagemaker boto3 awscli --upgrade  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ac353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, serializers, deserializers\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71542f98",
   "metadata": {},
   "source": [
    "## Step 2 pull and push the docker from Docker hub to ECR repository\n",
    "\n",
    "*Note: Please make sure you have the permission in AWS credential to push to ECR repository*\n",
    "\n",
    "This process may take a while, depends on the container size and your network bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1efb852",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# The name of our container\n",
    "repo_name=djlserving-byoc\n",
    "# Target container\n",
    "target_container=\"deepjavalibrary/djl-serving:deepspeed-nightly\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${repo_name}:latest\"\n",
    "echo \"Creating ECR repository ${fullname}\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${repo_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${repo_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin \"${account}.dkr.ecr.${region}.amazonaws.com\"\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "echo \"Start pulling container: ${target_container}\"\n",
    "\n",
    "docker pull ${target_container}\n",
    "docker tag ${target_container} ${fullname}\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81deac79",
   "metadata": {},
   "source": [
    "## Step 3: Start preparing model artifacts\n",
    "In LMI contianer, we expect some artifacts to help setting up the model\n",
    "- serving.properties (required): Defines the model server settings\n",
    "- model.py (optional): A python file to define the core inference logic\n",
    "- requirements.txt (optional): Any additional pip wheel need to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011bf5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.tensor_parallel_degree=1\n",
    "option.predict_timeout=1200\n",
    "option.model_id=cerebras/Cerebras-GPT-1.3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6798b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "from djl_python import Input, Output\n",
    "import torch\n",
    "import logging\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from djl_python.streaming_utils import StreamingUtils\n",
    "from paginator import DDBPaginator\n",
    "import uuid\n",
    "\n",
    "\n",
    "def load_model(properties):\n",
    "    model_location = properties['model_dir']\n",
    "    if \"model_id\" in properties:\n",
    "        model_location = properties['model_id']\n",
    "    logging.info(f\"Loading model in {model_location}\")\n",
    "    device = \"cuda:0\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_location, low_cpu_mem_usage=True, torch_dtype=torch.float16).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_location)\n",
    "    stream_generator = StreamingUtils.get_stream_generator(\"Accelerate\")\n",
    "    return model, tokenizer, stream_generator\n",
    "\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "stream_generator = None\n",
    "paginator = None\n",
    "\n",
    "def separate_inference(session_id, inputs):\n",
    "    prompt = inputs[\"prompt\"]\n",
    "    length = inputs[\"max_new_tokens\"]\n",
    "    generate_kwargs = dict(max_new_tokens=length, do_sample=True)\n",
    "    generator = stream_generator(model, tokenizer, prompt, **generate_kwargs)\n",
    "    generated = \"\"\n",
    "    iterator = 0\n",
    "    for text in generator:\n",
    "        generated += text[0]\n",
    "        if iterator == 5:\n",
    "            paginator.add_cache(session_id, generated)\n",
    "            iterator = 0\n",
    "        iterator += 1\n",
    "    paginator.add_cache(session_id, generated + \"<eos>\")\n",
    "\n",
    "\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    global model, tokenizer, stream_generator, paginator\n",
    "    if not model:\n",
    "        model, tokenizer, stream_generator = load_model(inputs.get_properties())\n",
    "        paginator = DDBPaginator(\"test_DB_Qing\")\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        # Model server makes an empty call to warmup the model on startup\n",
    "        return None\n",
    "    session_id = str(uuid.uuid4())\n",
    "    return Output().add({\"session_id\": session_id}).finalize(separate_inference, session_id, inputs.get_as_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e53e8c-9b3b-47a1-9afc-d1c8621269e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile paginator.py\n",
    "import boto3\n",
    "import logging\n",
    "\n",
    "\n",
    "class DDBPaginator:\n",
    "    DEFAULT_KEY_NAME = \"cache_id\"\n",
    "\n",
    "    def __init__(self, db_name):\n",
    "        self.db_name = db_name\n",
    "        self.ddb_client = boto3.client('dynamodb')\n",
    "        try:\n",
    "            self.ddb_client.describe_table(TableName=db_name)\n",
    "        except self.ddb_client.exceptions.ResourceNotFoundException:\n",
    "            logging.info(f\"Table {db_name} not found\")\n",
    "            self.ddb_client.create_table(TableName=db_name,\n",
    "                                         AttributeDefinitions=[{\n",
    "                                             'AttributeName': self.DEFAULT_KEY_NAME,\n",
    "                                             'AttributeType': 'S'\n",
    "                                         }, ],\n",
    "                                         KeySchema=[\n",
    "                                             {\n",
    "                                                 'AttributeName': self.DEFAULT_KEY_NAME,\n",
    "                                                 'KeyType': 'HASH'\n",
    "                                             }],\n",
    "                                         BillingMode='PAY_PER_REQUEST'\n",
    "                                         )\n",
    "            waiter = self.ddb_client.get_waiter('table_exists')\n",
    "            waiter.wait(TableName=db_name, WaiterConfig={'Delay': 1})\n",
    "\n",
    "    def add_cache(self, session_id, content):\n",
    "        return self.ddb_client.put_item(TableName=self.db_name,\n",
    "                                        Item={self.DEFAULT_KEY_NAME: {\"S\": session_id}, \"content\": {\"S\": content}})\n",
    "\n",
    "    def get_cache(self, session_id):\n",
    "        result = self.ddb_client.get_item(TableName=self.db_name, Key={self.DEFAULT_KEY_NAME: {\"S\": session_id}})\n",
    "        return result['Item']['content']['S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b50a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "boto3\n",
    "transformers==4.27.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0142973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir mymodel\n",
    "mv serving.properties mymodel/\n",
    "mv model.py mymodel/\n",
    "mv paginator.py mymodel/\n",
    "mv requirements.txt mymodel/\n",
    "tar czvf mymodel.tar.gz mymodel/\n",
    "rm -rf mymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58cf33",
   "metadata": {},
   "source": [
    "## Step 4: Start building SageMaker endpoint\n",
    "In this step, we will build SageMaker endpoint from scratch\n",
    "\n",
    "### 4.1 Upload artifact on S3 and create SageMaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1e5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_code_prefix = \"large-model-lmi/code\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "code_artifact = sess.upload_data(\"mymodel.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")\n",
    "\n",
    "repo_name=\"djlserving-byoc\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{repo_name}:latest\"\n",
    "env = {\"HUGGINGFACE_HUB_CACHE\": \"/tmp\", \"TRANSFORMERS_CACHE\": \"/tmp\"}\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=code_artifact, env=env, role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f39f6",
   "metadata": {},
   "source": [
    "### 4.2 Create SageMaker endpoint\n",
    "\n",
    "You need to specify the instance to use and endpoint names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e61cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.g5.2xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"lmi-model\")\n",
    "\n",
    "model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             endpoint_name=endpoint_name,\n",
    "             # container_startup_health_check_timeout=3600\n",
    "            )\n",
    "\n",
    "# our requests and responses will be in json format so we specify the serializer and the deserializer\n",
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializer=deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63ee65",
   "metadata": {},
   "source": [
    "## Step 5: Test and benchmark the inference\n",
    "\n",
    "In here, we use a SageMaker endpoint + DDB simple fetcher to get the response result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcef095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "session_id = predictor.predict({\"prompt\": [\"write a bubble sort algorithm in python\"], \"max_new_tokens\": 512})\n",
    "def get_stream(session_id):\n",
    "        ddb_client = boto3.client('dynamodb')\n",
    "        prev = 0\n",
    "        while True:\n",
    "            result = ddb_client.get_item(TableName=\"test_DB_Qing\", Key={\"cache_id\": {\"S\": session_id}})\n",
    "            if 'Item' in result:\n",
    "                text = result['Item']['content']['S']\n",
    "                print(text[prev:], end='')\n",
    "                prev = len(text)\n",
    "                if text.endswith('<eos>'):\n",
    "                    break\n",
    "            time.sleep(0.1)\n",
    "get_stream(session_id['session_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da05cbc-af43-4b36-bcff-0c6132f50b72",
   "metadata": {},
   "source": [
    "## Step 6: Make this as a single endpoint service\n",
    "\n",
    "in the previous example, we just demoed how to create an endpoint and use CLI to complete inference. Now, let's build a real-world application using Lambda and API-Gateway. Here we used an open-sourced toolkit by AWS called [Chalice](https://github.com/aws/chalice). It combines most commonly used Lambda/DynamoDB/APIGateway functions to deploy the stack easily.\n",
    "\n",
    "Chalice requires 4 major components:\n",
    "\n",
    "- `app.py`: Place to define your lambda function and related services\n",
    "- `requirements.txt`: pip wheel needed to drive the applicaiton\n",
    "- `.chalice/config.json`: a json file defines the generation logic and deployment stage\n",
    "- `.chalice/policy-<stage>.json`: a json file defines the policy that needs to attach to an IAM role of Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d9078-d909-46fc-a452-ed54f35f62ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install chalice requests --upgrade  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb795a3-bbec-42db-bf27-eae1607aa2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import serializers, deserializers\n",
    "from chalice import Chalice\n",
    "\n",
    "app = Chalice(app_name='stream_endpoint')\n",
    "TABLE_NAME=\"test_DB\"\n",
    "SM_ENDPOINT_NAME=\"lmi-model-deployment\"\n",
    "sm_predictor = None\n",
    "\n",
    "@app.route('/query', methods=['POST'])\n",
    "def run_inference():\n",
    "    body = app.current_request.json_body\n",
    "    if \"session_id\" in body:\n",
    "        return ddb_fetcher(body[\"session_id\"])\n",
    "    elif \"prompt\" in body:\n",
    "        return get_sm_predictor().predict(body)\n",
    "    else:\n",
    "        return {\"result\" : \"Error!\", \"_debug\": body}\n",
    "\n",
    "def ddb_fetcher(session_id):\n",
    "    ddb_client = boto3.client('dynamodb')\n",
    "    result = ddb_client.get_item(TableName=TABLE_NAME, Key={\"cache_id\": {\"S\": session_id}})\n",
    "    if 'Item' in result:\n",
    "        return {\"result\" : result['Item']['content']['S']}\n",
    "    return {\"result\": \"\", \"_debug\": result}\n",
    "\n",
    "\n",
    "def get_sm_predictor():\n",
    "    global sm_predictor\n",
    "    if sm_predictor is None:\n",
    "        sess = sagemaker.session.Session()\n",
    "        sm_predictor = sagemaker.Predictor(\n",
    "            endpoint_name=SM_ENDPOINT_NAME,\n",
    "            sagemaker_session=sess,\n",
    "            serializer=serializers.JSONSerializer(),\n",
    "            deserializer=deserializers.JSONDeserializer(),\n",
    "        )\n",
    "    return sm_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddbc81a-10c1-4435-9f64-1d5619ec2fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "boto3\n",
    "sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6fe20-62a4-44b8-8234-c26744146022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile config.json\n",
    "{\n",
    "  \"version\": \"2.0\",\n",
    "  \"app_name\": \"stream_endpoint\",\n",
    "  \"stages\": {\n",
    "    \"dev\": {\n",
    "      \"autogen_policy\": false,\n",
    "      \"api_gateway_stage\": \"api\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb7f8f4-6773-42ec-8805-f613f0b9a1ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile policy-dev.json\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Action\": [\n",
    "        \"logs:CreateLogGroup\",\n",
    "        \"logs:CreateLogStream\",\n",
    "        \"logs:PutLogEvents\"\n",
    "      ],\n",
    "      \"Resource\": \"arn:aws:logs:*:*:*\",\n",
    "      \"Effect\": \"Allow\"\n",
    "    },\n",
    "    {\n",
    "      \"Action\": [\n",
    "        \"dynamodb:GetItem\",\n",
    "        \"dynamodb:Scan\",\n",
    "        \"dynamodb:Query\"\n",
    "      ],\n",
    "      \"Resource\": [\n",
    "        \"arn:aws:dynamodb:*:*:table/test_DB*\"\n",
    "      ],\n",
    "      \"Effect\": \"Allow\"\n",
    "    },\n",
    "    {\n",
    "      \"Action\": [\n",
    "        \"sagemaker:ListEndpoints\",\n",
    "        \"sagemaker:InvokeEndpoint\"\n",
    "      ],\n",
    "      \"Resource\": [\n",
    "        \"arn:aws:sagemaker:*:*:endpoint/lmi*\"\n",
    "      ],\n",
    "      \"Effect\": \"Allow\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd4a5f-da1a-4e53-97b8-0dbfd40d7ba4",
   "metadata": {},
   "source": [
    "Now, let's do deployment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb685733-646b-47bf-bff2-c72cd22eb1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p deployment/.chalice\n",
    "mv app.py deployment/\n",
    "mv requirements.txt deployment/\n",
    "mv policy-dev.json deployment/.chalice/\n",
    "mv config.json deployment/.chalice/\n",
    "cd deployment/\n",
    "chalice deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd9042",
   "metadata": {},
   "source": [
    "## Clean up the environment\n",
    "\n",
    "If you have lambda and API gateway environment, do the following to clean up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d059e2-7f70-4908-9eed-ae00f12938de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd deployment/\n",
    "chalice delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d297acb-ef3c-4610-985e-a638a7694a06",
   "metadata": {},
   "source": [
    "Clean up the SageMaker endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d674b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598759b4-4ef0-4a1f-9b3c-c988c8a120c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
